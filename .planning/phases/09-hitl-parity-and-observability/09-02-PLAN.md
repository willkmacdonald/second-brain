---
phase: 09-hitl-parity-and-observability
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/src/second_brain/main.py
  - backend/src/second_brain/agents/middleware.py
autonomous: true
requirements:
  - OBSV-01
  - OBSV-02

must_haves:
  truths:
    - "Agent runs produce OTel spans with classification-specific attributes (bucket, confidence, status, item_id)"
    - "Tool calls produce child OTel spans with name and duration"
    - "enable_instrumentation() is called after configure_azure_monitor() so token usage metrics flow to App Insights"
    - "Endpoint-level trace spans cover the full capture lifecycle inside the async generator"
  artifacts:
    - path: "backend/src/second_brain/agents/middleware.py"
      provides: "OTel-instrumented AgentMiddleware and FunctionMiddleware"
      contains: "tracer.start_as_current_span"
    - path: "backend/src/second_brain/main.py"
      provides: "enable_instrumentation() call after configure_azure_monitor()"
      contains: "enable_instrumentation"
  key_links:
    - from: "backend/src/second_brain/main.py"
      to: "agent_framework.observability"
      via: "enable_instrumentation import and call"
      pattern: "from agent_framework.observability import enable_instrumentation"
    - from: "backend/src/second_brain/agents/middleware.py"
      to: "opentelemetry.trace"
      via: "tracer for custom spans"
      pattern: "from opentelemetry import trace"
---

<objective>
Upgrade the middleware skeleton from console logging to OTel spans with classification-specific attributes, and enable the agent-framework SDK's built-in instrumentation for automatic token usage tracking.

Purpose: Per-classification traces with token usage visible in Application Insights for monitoring and cost awareness.
Output: Structured OTel spans in middleware, enable_instrumentation() in main.py, endpoint-level trace spans in adapter.
</objective>

<execution_context>
@/Users/willmacdonald/.claude/get-shit-done/workflows/execute-plan.md
@/Users/willmacdonald/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/09-hitl-parity-and-observability/09-RESEARCH.md
@backend/src/second_brain/agents/middleware.py
@backend/src/second_brain/main.py
@backend/src/second_brain/streaming/adapter.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Enable SDK instrumentation and upgrade middleware to OTel spans</name>
  <files>
    backend/src/second_brain/main.py
    backend/src/second_brain/agents/middleware.py
  </files>
  <action>
    **1. Add `enable_instrumentation()` to `main.py`**:
    Right after the existing `configure_azure_monitor()` call (line 15), add:
    ```python
    from agent_framework.observability import enable_instrumentation  # noqa: E402
    enable_instrumentation()
    ```
    Order matters: Azure Monitor must configure exporters first, then agent-framework enables instrumentation on top. This automatically tracks `gen_ai.usage.input_tokens`, `gen_ai.usage.output_tokens`, and `gen_ai.operation.duration` as OTel metrics for every `get_response()` call. No additional code needed for OBSV-02.

    **2. Upgrade `AuditAgentMiddleware`** (`agents/middleware.py`):
    Replace console logging with OTel spans. Import `from opentelemetry import trace` and create `tracer = trace.get_tracer("second_brain.agents")` at module level.

    In `process()`:
    - Create a span `"classifier_agent_run"` using `tracer.start_as_current_span()`
    - Set attributes: `agent.name` = `"Classifier"`, `agent.duration_ms` = elapsed time in ms after `call_next()` completes
    - Keep the `logger.info()` calls as well (dual output: structured OTel + logs) but make them debug-level since OTel is now the primary observability channel

    **3. Upgrade `ToolTimingMiddleware`** (`agents/middleware.py`):
    Replace console logging with OTel spans.

    In `process()`:
    - Create a span `f"tool_{func_name}"` using `tracer.start_as_current_span()`
    - Set attributes: `tool.name` = func_name, `tool.duration_ms` = elapsed time in ms
    - After `call_next()`, inspect `context.result` for classification metadata:
      - If `func_name == "file_capture"` and `context.result` exists:
        - Parse the result (it's a dict with `bucket`, `confidence`, `item_id`, `status`)
        - Set span attributes: `classification.bucket`, `classification.confidence`, `classification.status`, `classification.item_id`
      - If `func_name == "transcribe_audio"` and `context.result` exists:
        - Set span attribute `transcription.success` = True
    - Keep `logger.debug()` calls alongside OTel spans

    **4. Update module docstring** (`agents/middleware.py`):
    Update the docstring to reflect that this is now the production observability layer (not a skeleton). Remove references to "Phase 9 replaces" since this IS Phase 9.

    **Important**: The `context.result` in `FunctionInvocationContext` may be the raw return value from the @tool function. The `file_capture` tool returns a dict like `{"bucket": "Ideas", "confidence": 0.85, "item_id": "abc-123", "status": "classified"}`. Access it via `context.result` directly -- if it's a `FunctionResult`, access `.value` or `.result`. Test which attribute name the SDK uses by checking the type.

    Actually, per 07-01 SUMMARY and research, `file_capture` returns a dict. The `FunctionInvocationContext.result` holds the `FunctionResult` object. Access the return value via `context.result.value` if `FunctionResult` wraps it, or check if `context.result` is directly the dict. Use defensive access:
    ```python
    raw_result = context.result
    if hasattr(raw_result, 'value'):
        raw_result = raw_result.value
    if isinstance(raw_result, dict):
        span.set_attribute("classification.bucket", raw_result.get("bucket", ""))
        # ... etc
    ```
  </action>
  <verify>
    Run `cd /Users/willmacdonald/Documents/Code/claude/second-brain/backend && uv run python3 -c "from second_brain.agents.middleware import AuditAgentMiddleware, ToolTimingMiddleware; from second_brain.main import app; print('OK')"` -- should print OK without import errors.
    Run `grep -c 'enable_instrumentation' src/second_brain/main.py` -- should be 2 (import + call).
    Run `grep -c 'tracer.start_as_current_span' src/second_brain/agents/middleware.py` -- should be 2 (one per middleware class).
  </verify>
  <done>
    `enable_instrumentation()` called after `configure_azure_monitor()` in main.py. `AuditAgentMiddleware` creates OTel span `classifier_agent_run` with `agent.name` and `agent.duration_ms`. `ToolTimingMiddleware` creates OTel span `tool_{func_name}` with `tool.name`, `tool.duration_ms`, and classification-specific attributes (`classification.bucket`, `classification.confidence`, `classification.status`, `classification.item_id`) when `file_capture` is the tool. Token usage automatically tracked by SDK instrumentation.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add endpoint-level trace spans in streaming adapter</name>
  <files>
    backend/src/second_brain/streaming/adapter.py
  </files>
  <action>
    **Per RESEARCH Pitfall 4**: OTel span context can be lost when crossing async generator boundaries. The span must be created INSIDE the async generator function (not in the endpoint handler) so it runs within the same task as `StreamingResponse`.

    **1. Add tracer to `adapter.py`**:
    Import `from opentelemetry import trace` and create `tracer = trace.get_tracer("second_brain.streaming")` at module level.

    **2. Wrap `stream_text_capture` body in a trace span**:
    Inside the function, wrap the entire try/except block in `with tracer.start_as_current_span("capture_text") as span:`. Set attributes:
    - `capture.type` = `"text"`
    - `capture.thread_id` = thread_id
    - `capture.run_id` = run_id
    After the stream completes (after outcome detection), add:
    - `capture.outcome` = `"classified"` / `"misunderstood"` / `"unresolved"` based on detected status
    - `capture.bucket` = bucket (if classified)
    - `capture.confidence` = confidence (if classified)

    **3. Wrap `stream_voice_capture` body in a trace span**:
    Same pattern with span name `"capture_voice"` and `capture.type` = `"voice"`.

    **4. Wrap `stream_follow_up_capture` body in a trace span** (if it exists from Plan 09-01):
    Same pattern with span name `"capture_follow_up"` and `capture.type` = `"follow_up"`. Add `capture.original_inbox_item_id` attribute.

    **Important**: The span wraps the ENTIRE generator body including the try/except. The span closes when the generator finishes (after COMPLETE event is yielded). This ensures middleware spans (from agent_run) are children of this endpoint span. Do NOT use `span.end()` manually -- the `with` block handles it.

    **Note on file ownership**: This plan's Task 2 modifies `adapter.py`, which Plan 09-01 also modifies. Since both plans are Wave 1 (parallel), there's a potential conflict. However, this task only ADDS the tracer import and wraps existing function bodies in `with` blocks -- it does NOT change the stream logic or add new functions. If Plan 09-01 runs first and adds `stream_follow_up_capture`, this task adds spans to it too. If this task runs first, Plan 09-01 adds `stream_follow_up_capture` without a span (acceptable -- it can be added in verification). The changes are structurally independent: Plan 09-01 adds a new function and modifies outcome detection, while this task wraps function bodies in spans.

    To minimize conflict: if `stream_follow_up_capture` does not yet exist when this task runs, skip adding a span to it and note in SUMMARY that the span should be added manually or in a gap closure.
  </action>
  <verify>
    Run `cd /Users/willmacdonald/Documents/Code/claude/second-brain/backend && uv run python3 -c "from second_brain.streaming.adapter import stream_text_capture, stream_voice_capture; print('OK')"` -- should print OK.
    Run `grep -c 'start_as_current_span' src/second_brain/streaming/adapter.py` -- should be >= 2 (text + voice capture spans).
  </verify>
  <done>
    `stream_text_capture` wrapped in `capture_text` OTel span with `capture.type`, `capture.thread_id`, `capture.outcome`, `capture.bucket`, `capture.confidence` attributes. `stream_voice_capture` wrapped in `capture_voice` OTel span. Spans are created inside the async generator (not endpoint handler) to prevent context loss across async boundaries. Middleware spans are children of these endpoint spans via OTel parent-child hierarchy.
  </done>
</task>

</tasks>

<verification>
1. `enable_instrumentation()` is called after `configure_azure_monitor()` in main.py
2. `AuditAgentMiddleware` creates OTel span `classifier_agent_run` with agent attributes
3. `ToolTimingMiddleware` creates OTel span `tool_{func_name}` with classification attributes when file_capture runs
4. `stream_text_capture` and `stream_voice_capture` have endpoint-level OTel spans
5. All spans use `tracer.start_as_current_span()` (not manual span management)
6. Token usage metrics automatically tracked via `enable_instrumentation()` (OBSV-02)
</verification>

<success_criteria>
Application Insights receives structured OTel traces from Foundry agent runs with per-classification visibility (bucket, confidence, status, item_id, duration). Token usage metrics are automatically tracked by the SDK's built-in instrumentation layer. Endpoint-level spans correctly parent middleware spans.
</success_criteria>

<output>
After completion, create `.planning/phases/09-hitl-parity-and-observability/09-02-SUMMARY.md`
</output>
