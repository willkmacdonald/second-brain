---
phase: 01-backend-foundation
plan: 03
type: execute
wave: 3
depends_on:
  - "01-01"
  - "01-02"
files_modified:
  - backend/src/second_brain/auth.py
  - backend/src/second_brain/main.py
  - backend/tests/test_auth.py
  - backend/tests/test_integration.py
autonomous: true
requirements:
  - INFRA-05

must_haves:
  truths:
    - "Requests without an API key are rejected with 401"
    - "Requests with an invalid API key are rejected with 401"
    - "Requests with a valid API key are accepted and processed normally"
    - "The /health endpoint is accessible without authentication"
    - "Failed auth attempts are logged with IP and timestamp"
    - "The full stack works end-to-end: auth -> AG-UI -> agent -> Cosmos CRUD tools"
  artifacts:
    - path: "backend/src/second_brain/auth.py"
      provides: "API key authentication middleware with security logging"
      contains: "APIKeyMiddleware"
    - path: "backend/tests/test_auth.py"
      provides: "Tests for auth middleware behavior"
      contains: "test_missing_api_key"
    - path: "backend/tests/test_integration.py"
      provides: "End-to-end integration test for the full stack"
      contains: "test_"
  key_links:
    - from: "backend/src/second_brain/main.py"
      to: "backend/src/second_brain/auth.py"
      via: "app.add_middleware(APIKeyMiddleware) wrapping all routes"
      pattern: "APIKeyMiddleware"
    - from: "backend/src/second_brain/auth.py"
      to: "app.state.api_key"
      via: "Reads API key fetched from Azure Key Vault at startup (stored on app.state)"
      pattern: "api_key"
---

<objective>
Add API key authentication middleware with security logging, then verify the complete Phase 1 stack end-to-end.

Purpose: Protect the AG-UI endpoint so only requests with a valid API key are processed. Establish the security logging foundation for failed auth attempts. Prove the full stack works: auth -> AG-UI -> echo agent -> Cosmos CRUD tools -> response streaming.

Output: API key middleware on all routes (except /health), security logging on failures, comprehensive auth tests, and an integration test validating the full stack.
</objective>

<execution_context>
@/Users/willmacdonald/.claude/get-shit-done/workflows/execute-plan.md
@/Users/willmacdonald/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-backend-foundation/01-RESEARCH.md
@.planning/phases/01-backend-foundation/01-CONTEXT.md
@.planning/phases/01-backend-foundation/01-01-SUMMARY.md
@.planning/phases/01-backend-foundation/01-02-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create API key authentication middleware with security logging</name>
  <files>
    backend/src/second_brain/auth.py
    backend/src/second_brain/main.py
    backend/tests/test_auth.py
  </files>
  <action>
    **auth.py:**
    Create an `APIKeyMiddleware` class (Starlette `BaseHTTPMiddleware`). This class is justified per CLAUDE.md — it is a framework pattern (middleware).

    Per the locked CONTEXT.md decisions:
    - Key passed via `Authorization: Bearer <key>` header (NOT `X-API-Key` — the CONTEXT decision overrides the research example which used `X-API-Key`)
    - Failed auth attempts logged with IP/timestamp for security auditing
    - Push notification on repeated failures DEFERRED to Phase 8 — only logging for now

    Implementation:
    - `__init__(self, app, api_key: str)`: Store the expected API key
    - `async def dispatch(self, request: Request, call_next)`:
      1. Allow `/health` and `/docs` and `/openapi.json` without auth
      2. Extract `Authorization` header, expect format `Bearer <key>`
      3. If header missing or key invalid:
         - Log warning with `logging.getLogger("second_brain.auth")`: include client IP (`request.client.host`), timestamp (ISO format), path, and "AUTH_FAILED" marker for easy log searching
         - Return 401 JSON response: `{"detail": "Invalid or missing API key"}`
      4. If valid: call `await call_next(request)`
    - Use Python `logging` module (not print — per CLAUDE.md)

    IMPORTANT: The API key is NOT in pydantic-settings. It is fetched from Azure Key Vault at startup (Plan 01-01) and stored on `app.state.api_key`. The middleware constructor receives it from `app.state.api_key`, not from `settings.api_key`.

    **main.py updates:**
    - Import `APIKeyMiddleware` from `auth`
    - Call `app.add_middleware(APIKeyMiddleware, api_key=app.state.api_key)` INSIDE the lifespan context manager, AFTER the Key Vault fetch sets `app.state.api_key` and BEFORE the `yield`. Do NOT call at module level — `app.state.api_key` does not exist until the lifespan runs.
    - This must come AFTER `add_agent_framework_fastapi_endpoint()` so it wraps the AG-UI endpoint (per research Pitfall 3)
    - The API key comes from Azure Key Vault (Plan 01-01), NOT from pydantic-settings

    **tests/test_auth.py:**
    - `test_missing_api_key_returns_401`: POST to `/api/ag-ui` with no Authorization header -> 401
    - `test_invalid_api_key_returns_401`: POST with `Authorization: Bearer wrong-key` -> 401
    - `test_valid_api_key_passes`: POST with `Authorization: Bearer <correct-key>` -> not 401 (200 or SSE stream)
    - `test_health_no_auth_required`: GET `/health` with no auth -> 200
    - `test_malformed_auth_header_returns_401`: POST with `Authorization: NotBearer key` -> 401
    - `test_failed_auth_logs_ip_and_timestamp`: Verify that failed auth emits a log with "AUTH_FAILED", client IP, and ISO timestamp (use `caplog` fixture)
    - All tests use mocked dependencies (no real Azure calls)
    - Set a test API key via environment variable or fixture override

    Run: `cd backend && uv run pytest tests/test_auth.py -v`
  </action>
  <verify>
    1. `cd backend && uv run pytest tests/test_auth.py -v` — all auth tests pass
    2. `cd backend && uv run ruff check . && uv run ruff format --check .` — no lint/format issues
    3. `cd backend && uv run python -c "from second_brain.auth import APIKeyMiddleware; print('Auth OK')"` — imports
  </verify>
  <done>
    APIKeyMiddleware rejects requests without valid `Authorization: Bearer <key>` header with 401. /health is accessible without auth. Failed attempts are logged with IP, timestamp, and AUTH_FAILED marker. All auth tests pass.
  </done>
</task>

<task type="auto">
  <name>Task 2: End-to-end integration test validating the full Phase 1 stack</name>
  <files>
    backend/tests/test_integration.py
    backend/tests/conftest.py
  </files>
  <action>
    **tests/test_integration.py:**
    Create integration tests that validate the complete Phase 1 stack works together. These tests use mocked Azure services (no real LLM or Cosmos calls) but exercise the full middleware -> routing -> agent -> tools pipeline.

    Tests:
    - `test_full_stack_auth_to_sse_response`:
      1. Create test app with all middleware and AG-UI endpoint
      2. Send POST to `/api/ag-ui` with valid `Authorization: Bearer <test-key>` and AG-UI message body
      3. Assert response is SSE (content-type: text/event-stream)
      4. Assert response contains RUN_STARTED and RUN_FINISHED events
    - `test_auth_blocks_agui_endpoint`:
      1. Send POST to `/api/ag-ui` without auth header
      2. Assert 401 response
      3. Verify the agent was NOT invoked (mock not called)
    - `test_health_bypasses_auth`:
      1. Send GET to `/health` without auth
      2. Assert 200 with `{"status": "ok"}`

    **tests/conftest.py updates:**
    - Add an `app_with_mocks` fixture that creates the full FastAPI app with:
      - Mocked `CosmosManager` (from Plan 01-02)
      - Mocked `AzureOpenAIChatClient` (from Plan 01-01)
      - Real `APIKeyMiddleware` with a known test key
      - Real AG-UI endpoint registration
    - Add an `async_client` fixture using `httpx.AsyncClient` with `ASGITransport(app=app_with_mocks)`
    - Ensure test API key is set to a known value like `"test-api-key-12345"`

    Run the full test suite: `cd backend && uv run pytest tests/ -v`

    After all tests pass, run the complete quality check:
    - `cd backend && uv run ruff check . && uv run ruff format --check .`
    - `cd backend && uv run pytest tests/ -v --tb=short`
  </action>
  <verify>
    1. `cd backend && uv run pytest tests/test_integration.py -v` — all integration tests pass
    2. `cd backend && uv run pytest tests/ -v` — ALL tests pass (health, AG-UI, CRUD, auth, integration)
    3. `cd backend && uv run ruff check . && uv run ruff format --check .` — clean
    4. Test count is reasonable (expect 15+ tests across all test files)
  </verify>
  <done>
    Full Phase 1 stack validated end-to-end: auth middleware correctly gates the AG-UI endpoint, health endpoint bypasses auth, the echo agent processes requests and returns SSE responses, CRUD tools are available to the agent. All tests pass. No lint issues.
  </done>
</task>

</tasks>

<verification>
1. Unauthenticated requests to /api/ag-ui return 401
2. Authenticated requests to /api/ag-ui return SSE responses
3. /health works without authentication
4. Failed auth attempts are logged with IP and timestamp
5. Authorization: Bearer <key> format is enforced
6. Full test suite passes: `cd backend && uv run pytest tests/ -v`
7. No lint issues: `cd backend && uv run ruff check .`
</verification>

<success_criteria>
- API key middleware protects all routes except /health
- `Authorization: Bearer <key>` header format enforced
- Failed auth logged with IP, timestamp, AUTH_FAILED marker
- Integration tests prove full stack: auth -> AG-UI -> agent -> tools -> SSE response
- All pytest tests pass (15+ tests across all test files)
- Zero ruff lint/format issues
</success_criteria>

<output>
After completion, create `.planning/phases/01-backend-foundation/01-03-SUMMARY.md`
</output>
