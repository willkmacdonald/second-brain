---
phase: 07-classifier-agent-baseline
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/src/second_brain/tools/classification.py
  - backend/src/second_brain/tools/transcription.py
  - backend/src/second_brain/agents/classifier.py
  - backend/src/second_brain/agents/middleware.py
  - backend/src/second_brain/config.py
  - backend/.env.example
  - backend/tests/test_classification.py
  - backend/pyproject.toml
autonomous: true
requirements: [AGNT-01, AGNT-02, AGNT-05, AGNT-06]

must_haves:
  truths:
    - "file_capture tool writes to Cosmos DB Inbox + bucket container and returns a structured dict"
    - "transcribe_audio tool calls gpt-4o-transcribe via AsyncAzureOpenAI and returns transcript text"
    - "AuditAgentMiddleware and ToolTimingMiddleware classes exist and implement the correct process() signatures"
    - "Classifier agent instructions cover all three outcomes (classified, pending, misunderstood) with file_capture as the single tool"
    - "ensure_classifier_agent function checks stored agent ID and creates-if-missing via Foundry API"
  artifacts:
    - path: "backend/src/second_brain/tools/classification.py"
      provides: "ClassifierTools with file_capture @tool returning dict"
      contains: "file_capture"
    - path: "backend/src/second_brain/tools/transcription.py"
      provides: "TranscriptionTools with transcribe_audio @tool"
      contains: "transcribe_audio"
    - path: "backend/src/second_brain/agents/classifier.py"
      provides: "ensure_classifier_agent function + CLASSIFIER_INSTRUCTIONS"
      contains: "ensure_classifier_agent"
    - path: "backend/src/second_brain/agents/middleware.py"
      provides: "AuditAgentMiddleware + ToolTimingMiddleware"
      contains: "AuditAgentMiddleware"
    - path: "backend/tests/test_classification.py"
      provides: "Updated tests for file_capture dict returns and misunderstood status"
      contains: "file_capture"
  key_links:
    - from: "backend/src/second_brain/tools/classification.py"
      to: "backend/src/second_brain/db/cosmos.py"
      via: "CosmosManager.get_container() for Inbox and bucket writes"
      pattern: "self._cosmos.get_container"
    - from: "backend/src/second_brain/tools/transcription.py"
      to: "openai.AsyncAzureOpenAI"
      via: "audio.transcriptions.create() with gpt-4o-transcribe"
      pattern: "self._openai.audio.transcriptions.create"
    - from: "backend/src/second_brain/agents/classifier.py"
      to: "agent_framework.azure.AzureAIAgentClient"
      via: "agents_client.get_agent() and agents_client.create_agent()"
      pattern: "agents_client\\.(get_agent|create_agent)"
---

<objective>
Rewrite classification tools (file_capture), create transcription tool, create middleware, and rewrite the classifier module for Foundry agent registration.

Purpose: Build all the modules that Phase 7 Plan 02 wires into the FastAPI lifespan. These are the building blocks -- tools, middleware, and agent management -- that exist independently before being connected.

Output: Rewritten classification.py, new transcription.py, new middleware.py, rewritten classifier.py, updated tests
</objective>

<execution_context>
@/Users/willmacdonald/.claude/get-shit-done/workflows/execute-plan.md
@/Users/willmacdonald/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-classifier-agent-baseline/07-CONTEXT.md
@.planning/phases/07-classifier-agent-baseline/07-RESEARCH.md
@.planning/phases/06-foundry-infrastructure/06-02-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Rewrite classification tools and create transcription tool</name>
  <files>
    backend/src/second_brain/tools/classification.py
    backend/src/second_brain/tools/transcription.py
    backend/src/second_brain/config.py
    backend/.env.example
    backend/pyproject.toml
  </files>
  <action>
**Rewrite `classification.py`** -- replace `ClassificationTools` with `ClassifierTools`:

1. Rename class from `ClassificationTools` to `ClassifierTools` (per research pattern)
2. Replace `classify_and_file` with `file_capture` tool (per CONTEXT.md locked decision):
   - Parameters: `text` (str), `bucket` (str), `confidence` (float), `status` (str: "classified"/"pending"/"misunderstood"), `title` (str, default "Untitled")
   - Use `Annotated[type, Field(description="...")]` for parameter descriptions (Foundry uses these for tool schema generation)
   - Add `@tool(approval_mode="never_require")` decorator
   - Return structured dict: `{"bucket": "Ideas", "confidence": 0.85, "item_id": "..."}` on success
   - Return error dict: `{"error": "...", "detail": "..."}` on failure -- wrap all Cosmos operations in try/except, log at WARNING, NO exceptions raised
   - For misunderstood status: write ONLY to Inbox (no bucket container write), set `classificationMeta=None` and `filedRecordId=None`
   - For classified/pending: write to both Inbox AND bucket container (same as v1 logic)
   - Update `agentChain` from `["Orchestrator", "Classifier"]` to `["Classifier"]` (no orchestrator in v2)
   - Keep `allScores` as empty dict `{}` -- agent-determined scores, not tracking per-bucket in v2
   - Keep confidence clamping (0.0-1.0) and the 0.0-fallback-to-0.75 logic from v1
   - Remove `_derive_scores_from_bucket()` helper (no longer needed with empty allScores)
3. **Delete** `request_misunderstood` method entirely -- misunderstood is now a `file_capture(status="misunderstood")` call
4. **Delete** `mark_as_junk` method entirely -- junk and misunderstood are unified (CONTEXT.md: "no separate junk status")
5. Keep the `VALID_BUCKETS` constant

**Create `transcription.py`** -- new file:

1. Create `TranscriptionTools` class with `__init__(self, openai_client: AsyncAzureOpenAI, blob_manager: BlobStorageManager)`
2. Add `transcribe_audio` tool with `@tool(approval_mode="never_require")`:
   - Parameter: `blob_url` (str) -- Azure Blob Storage URL of the voice recording
   - Downloads audio bytes from Blob Storage using `BlobClient.from_blob_url()` with the app's credential
   - Calls `self._openai.audio.transcriptions.create(model=deployment_name, file=("recording.m4a", audio_bytes, "audio/m4a"))` where `deployment_name` comes from config
   - Returns transcript text string on success
   - Returns error string `"Transcription error: {exc}"` on failure (per CONTEXT.md: no exceptions)
   - The `_download_blob` helper method should accept the credential from the constructor rather than creating a new one

3. The `TranscriptionTools.__init__` should also accept a `credential` parameter (the app's `AsyncDefaultAzureCredential`) for blob download auth

**Update `config.py`**:
- Add `azure_openai_transcription_deployment: str = "gpt-4o-transcribe"` for the transcription model deployment name (per research open question #2: store as env var rather than hardcode)
- Add `azure_openai_endpoint: str = ""` for the Azure OpenAI endpoint used by AsyncAzureOpenAI (the transcription API uses a different endpoint from the Foundry project endpoint)

**Update `.env.example`**:
- Add `AZURE_OPENAI_TRANSCRIPTION_DEPLOYMENT=gpt-4o-transcribe`
- Add `AZURE_OPENAI_ENDPOINT=https://your-openai-resource.openai.azure.com/`

**Update `pyproject.toml`**:
- Add `"openai"` as a direct dependency (currently only transitive via azure-ai-agents). The `transcribe_audio` tool directly imports `AsyncAzureOpenAI` from the `openai` package.
- Add ruff per-file-ignore for `transcription.py`: `"src/second_brain/tools/transcription.py" = ["N815"]` (if needed for camelCase fields)

**Import notes:**
- `from agent_framework import tool` (not `agent_framework.tool`)
- `from pydantic import Field` for Annotated descriptions
- `from openai import AsyncAzureOpenAI` for transcription client
- `from azure.storage.blob.aio import BlobClient` for blob download
  </action>
  <verify>
Run `cd /Users/willmacdonald/Documents/Code/claude/second-brain/backend && python3 -c "from second_brain.tools.classification import ClassifierTools; from second_brain.tools.transcription import TranscriptionTools; print('imports OK')"` -- must succeed.

Run `cd /Users/willmacdonald/Documents/Code/claude/second-brain/backend && ruff check src/second_brain/tools/classification.py src/second_brain/tools/transcription.py src/second_brain/config.py` -- no errors.
  </verify>
  <done>
`ClassifierTools.file_capture` replaces `classify_and_file` with dict returns. `mark_as_junk` and `request_misunderstood` are deleted. `TranscriptionTools.transcribe_audio` exists and imports cleanly. Config has transcription deployment name.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create middleware, rewrite classifier module, and update tests</name>
  <files>
    backend/src/second_brain/agents/middleware.py
    backend/src/second_brain/agents/classifier.py
    backend/tests/test_classification.py
  </files>
  <action>
**Create `middleware.py`** -- new file in `agents/`:

1. `AuditAgentMiddleware(AgentMiddleware)`:
   - `async def process(self, context: AgentContext, call_next: Callable[[], Awaitable[None]]) -> None`
   - Log agent run start with `logger.info("[Agent] Run started: thread=%s", ...)` using Foundry's built-in thread/run IDs from context (per CONTEXT.md: use Foundry IDs for correlation)
   - Call `await call_next()`
   - Log agent run completion with elapsed time: `logger.info("[Agent] Run completed in %.3fs", elapsed)`
   - If the middleware `call_next()` with no args fails at runtime (per research open question #1), fall back to `call_next(context)` -- flag this as an empirical finding

2. `ToolTimingMiddleware(FunctionMiddleware)`:
   - `async def process(self, context: FunctionInvocationContext, call_next: Callable[[], Awaitable[None]]) -> None`
   - Log tool call start: `logger.info("[Tool] Calling %s", context.function.name)`
   - Call `await call_next()` and measure elapsed time
   - After call_next, inspect `context.result`:
     - If result is a dict with "bucket" key (file_capture success): log structured fields `bucket, confidence, status, item_id` at INFO level (per CONTEXT.md: structured fields queryable in AppInsights)
     - If result is a dict with "error" key: log at WARNING level (per CONTEXT.md: tool failures at WARNING)
     - Otherwise: log generic completion with timing
   - No token usage tracking (deferred to Phase 9 per CONTEXT.md)

Imports: `from agent_framework import AgentMiddleware, FunctionMiddleware` and the context types. Use `import time` for `time.monotonic()`.

**Rewrite `classifier.py`**:

1. Delete the entire existing `create_classifier_agent` function and all its contents
2. Remove imports: `Agent`, `AzureOpenAIChatClient` (v1 types no longer used)
3. Add `CLASSIFIER_INSTRUCTIONS` constant -- a multi-line string with the Classifier's instructions:
   - Light persona: "You are Will's second brain classifier."
   - Detailed bucket definitions with boundaries, edge cases, and overlap rules (port from v1 instructions but refined per CONTEXT.md)
   - Three outcomes: classified (>= 0.6), pending (0.3-0.59), misunderstood (< 0.3 or can't determine)
   - Junk and misunderstood are unified -- no separate junk status
   - Multi-bucket rule: strongest match wins, no priority hierarchy
   - Voice capture instruction: "For voice captures, call transcribe_audio first, read the transcript, then call file_capture"
   - Rules: ALWAYS call file_capture or transcribe_audio, never respond without a tool call
   - NOTE in code comment: "Initial instructions used at agent creation. Portal is the source of truth after first creation."

4. Add `ensure_classifier_agent()` async function:
   - Signature: `async def ensure_classifier_agent(foundry_client: AzureAIAgentClient, stored_agent_id: str) -> str`
   - If `stored_agent_id` is non-empty: call `foundry_client.agents_client.get_agent(stored_agent_id)` to verify it exists. If valid, log and return the ID. If exception (not found), log WARNING and fall through to creation.
   - If no valid ID: call `foundry_client.agents_client.create_agent(model="gpt-4o", name="Classifier", instructions=CLASSIFIER_INSTRUCTIONS)` to create a new agent.
   - Log the new ID prominently: `logger.info("NEW Classifier agent: id=%s -- UPDATE AZURE_AI_CLASSIFIER_AGENT_ID in .env", new_agent.id)`
   - Return the agent ID (either existing or newly created)
   - No try/except around the overall function -- if agent registration fails, it should propagate up to the lifespan and crash the app (per CONTEXT.md: hard dependency)

**Update `test_classification.py`**:

1. Update all imports from `ClassificationTools` to `ClassifierTools`
2. Update helper `_make_tools` to construct `ClassifierTools` instead of `ClassificationTools`
3. Rewrite `test_classify_and_file_high_confidence` -> `test_file_capture_classified`:
   - Call `tools.file_capture(text="Build the new dashboard", bucket="Projects", confidence=0.85, status="classified", title="New Dashboard")`
   - Assert result is a dict: `{"bucket": "Projects", "confidence": 0.85, "item_id": "<uuid>"}`
   - Assert Inbox write with `status="classified"`, classificationMeta present
   - Assert Projects container write with correct title and inboxRecordId

4. Rewrite `test_classify_and_file_low_confidence` -> `test_file_capture_pending`:
   - Call `tools.file_capture(text=..., bucket="People", confidence=0.45, status="pending", title=...)`
   - Assert result dict with confidence=0.45
   - Assert Inbox write with `status="pending"`
   - Assert bucket container write still happens for pending status

5. Add new `test_file_capture_misunderstood`:
   - Call `tools.file_capture(text="Xyzzy", bucket="Admin", confidence=0.0, status="misunderstood", title="Untitled")`
   - Assert result dict (file_capture always returns dict on success)
   - Assert Inbox write with `status="misunderstood"`, `classificationMeta=None`, `filedRecordId=None`
   - Assert NO bucket container writes (misunderstood items only go to Inbox)

6. Update `test_classify_and_file_each_bucket` to use `file_capture` with new parameter names
7. Update `test_classify_and_file_invalid_bucket` -> `test_file_capture_invalid_bucket`: assert error dict `{"error": "invalid_bucket", ...}`
8. Update confidence clamping tests: assert dict return instead of string
9. Update `test_classification_meta_fields`: verify `agentChain` is `["Classifier"]` (not `["Orchestrator", "Classifier"]`)
10. Update `test_bidirectional_links`: use new `file_capture` parameter names
11. Delete `test_mark_as_junk` -- mark_as_junk tool no longer exists
12. Delete `test_request_misunderstood_*` tests -- request_misunderstood tool no longer exists
  </action>
  <verify>
Run `cd /Users/willmacdonald/Documents/Code/claude/second-brain/backend && python3 -c "from second_brain.agents.middleware import AuditAgentMiddleware, ToolTimingMiddleware; from second_brain.agents.classifier import ensure_classifier_agent, CLASSIFIER_INSTRUCTIONS; print('imports OK')"` -- must succeed.

Run `cd /Users/willmacdonald/Documents/Code/claude/second-brain/backend && python3 -m pytest tests/test_classification.py -v` -- all tests pass.

Run `cd /Users/willmacdonald/Documents/Code/claude/second-brain/backend && ruff check src/second_brain/agents/ src/second_brain/tools/ tests/test_classification.py` -- no errors.
  </verify>
  <done>
AuditAgentMiddleware and ToolTimingMiddleware implement AgentMiddleware/FunctionMiddleware with correct process() signatures. Classifier module has ensure_classifier_agent + CLASSIFIER_INSTRUCTIONS. All unit tests pass with file_capture dict returns. mark_as_junk and request_misunderstood tests are removed.
  </done>
</task>

</tasks>

<verification>
1. `python3 -c "from second_brain.tools.classification import ClassifierTools; from second_brain.tools.transcription import TranscriptionTools; from second_brain.agents.classifier import ensure_classifier_agent; from second_brain.agents.middleware import AuditAgentMiddleware, ToolTimingMiddleware; print('All modules import cleanly')"` -- succeeds
2. `python3 -m pytest tests/test_classification.py -v` -- all tests pass
3. `ruff check src/ tests/` -- no lint errors in modified files
4. `grep -r "classify_and_file\|mark_as_junk\|request_misunderstood" src/second_brain/tools/classification.py` -- returns nothing (old tools deleted)
5. `grep -r "AzureOpenAIChatClient" src/second_brain/agents/classifier.py` -- returns nothing (old import deleted)
</verification>

<success_criteria>
- ClassifierTools.file_capture exists and returns structured dicts
- TranscriptionTools.transcribe_audio exists with gpt-4o-transcribe integration
- AuditAgentMiddleware and ToolTimingMiddleware implement correct middleware interfaces
- ensure_classifier_agent creates-if-missing via Foundry API
- CLASSIFIER_INSTRUCTIONS covers all three outcomes (classified, pending, misunderstood)
- All unit tests pass with updated assertions for dict returns
- No references to classify_and_file, mark_as_junk, or request_misunderstood in tools module
</success_criteria>

<output>
After completion, create `.planning/phases/07-classifier-agent-baseline/07-01-SUMMARY.md`
</output>
