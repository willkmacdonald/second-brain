---
phase: 04-hitl-clarification-and-ag-ui-streaming
plan: 02
type: execute
wave: 2
depends_on: ["04-01"]
files_modified:
  - mobile/app/_layout.tsx
  - mobile/app/(tabs)/_layout.tsx
  - mobile/app/(tabs)/index.tsx
  - mobile/app/capture/text.tsx
  - mobile/lib/types.ts
  - mobile/lib/ag-ui-client.ts
  - mobile/components/AgentSteps.tsx
autonomous: true
requirements: [CAPT-02, CLAS-04]

must_haves:
  truths:
    - "User sees step dots (horizontal pills) below the text input showing Orchestrator -> Classifier, each lighting up as agents activate"
    - "Streamed text response appears live word-by-word below the step dots as the agent generates it"
    - "After successful classification, result auto-resets after 2-3 seconds and input clears for next capture"
    - "When confidence is low, clarification question appears inline below step dots with 4 bucket buttons (People / Projects / Ideas / Admin)"
    - "Tapping a bucket button sends the selection via /api/ag-ui/respond and files immediately"
    - "Bottom tab bar has Capture and Inbox tabs, Capture is the default tab"
    - "Existing 4 large capture buttons (Voice, Photo, Video, Text) are preserved on the capture tab"
  artifacts:
    - path: "mobile/app/_layout.tsx"
      provides: "Root layout with Stack wrapping tabs and conversation route"
      contains: "Stack"
    - path: "mobile/app/(tabs)/_layout.tsx"
      provides: "Tab layout with Capture and Inbox tabs"
      contains: "Tabs"
    - path: "mobile/app/(tabs)/index.tsx"
      provides: "Capture tab (moved from app/index.tsx)"
      contains: "CaptureButton"
    - path: "mobile/app/capture/text.tsx"
      provides: "Text capture with step dots, streaming text, inline HITL clarification"
      contains: "AgentSteps"
    - path: "mobile/lib/types.ts"
      provides: "Updated AG-UI event types with streaming callbacks"
      contains: "StreamingCallbacks"
    - path: "mobile/lib/ag-ui-client.ts"
      provides: "Updated SSE client with step events, HITL handling, sendClarification function"
      contains: "sendClarification"
    - path: "mobile/components/AgentSteps.tsx"
      provides: "Visual step indicator with horizontal pills"
      contains: "AgentSteps"
  key_links:
    - from: "mobile/lib/ag-ui-client.ts"
      to: "/api/ag-ui and /api/ag-ui/respond"
      via: "SSE POST requests"
      pattern: "sendCapture|sendClarification"
    - from: "mobile/app/capture/text.tsx"
      to: "mobile/components/AgentSteps.tsx"
      via: "component import"
      pattern: "AgentSteps"
    - from: "mobile/app/capture/text.tsx"
      to: "mobile/lib/ag-ui-client.ts"
      via: "sendCapture with StreamingCallbacks"
      pattern: "sendCapture"
---

<objective>
Mobile real-time capture UX with tab navigation, step dots, streaming text, and inline HITL clarification

Purpose: Transform the fire-and-forget capture screen into a real-time interactive experience where Will sees agents processing his capture (step dots), reads the streamed response live (word-by-word), and can resolve low-confidence classifications by tapping a bucket button inline -- all without leaving the capture screen.

Output: Tab navigation (Capture + Inbox), AgentSteps component, updated SSE client with streaming callbacks + sendClarification, updated text capture screen with step dots + streaming text + bucket buttons for HITL.
</objective>

<execution_context>
@/Users/willmacdonald/.claude/get-shit-done/workflows/execute-plan.md
@/Users/willmacdonald/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-hitl-clarification-and-ag-ui-streaming/04-CONTEXT.md
@.planning/phases/04-hitl-clarification-and-ag-ui-streaming/04-RESEARCH.md
@.planning/phases/04-hitl-clarification-and-ag-ui-streaming/04-01-SUMMARY.md
@.planning/phases/03-text-classification-pipeline/03-02-SUMMARY.md

# Key source files to read before implementing:
@mobile/app/_layout.tsx
@mobile/app/index.tsx
@mobile/app/capture/text.tsx
@mobile/lib/types.ts
@mobile/lib/ag-ui-client.ts
@mobile/components/CaptureButton.tsx
@mobile/constants/config.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Tab navigation, types, and SSE client with streaming callbacks</name>
  <files>
    mobile/app/_layout.tsx
    mobile/app/(tabs)/_layout.tsx
    mobile/app/(tabs)/index.tsx
    mobile/app/index.tsx
    mobile/lib/types.ts
    mobile/lib/ag-ui-client.ts
  </files>
  <action>
    **Navigation restructure for tabs (per locked decisions):**

    1. **Create `mobile/app/(tabs)/_layout.tsx`** -- Tab bar layout with Capture and Inbox tabs:
       - Use `expo-router` Tabs component.
       - Two tabs: "Capture" (default, index) and "Inbox".
       - Tab bar style: dark theme matching app (`backgroundColor: "#0f0f23"`).
       - Tab icons: use simple text/unicode (no icon library needed for MVP). Capture: pencil-like, Inbox: folder-like.
       - Active tab color: `#4a90d9` (matching existing send button blue).
       - Inactive tab color: `#666`.
       - Inbox tab supports `tabBarBadge` prop for pending count (set to undefined initially, Plan 04-03 will populate).

    2. **Create `mobile/app/(tabs)/index.tsx`** -- Move the current `app/index.tsx` capture screen content here:
       - Copy the entire CaptureScreen component from `app/index.tsx`.
       - Keep all 4 capture buttons (Voice, Text, Photo, Video) per locked decision.
       - No functional changes -- just moved into tab structure.

    3. **Update `mobile/app/_layout.tsx`** -- Root layout becomes a Stack wrapping tabs:
       - Stack contains `(tabs)` group and `capture/text` modal and `conversation/[threadId]` screen.
       - Keep the existing `capture/text` modal screen config.
       - Add `conversation/[threadId]` screen declaration (component won't exist yet, Plan 04-03 creates it).
       - Remove the old `index` screen declaration (now inside tabs).

    4. **Delete or replace `mobile/app/index.tsx`** -- This file is replaced by `(tabs)/index.tsx`. Either delete it or make it redirect to tabs. With expo-router, the `(tabs)/index.tsx` should handle the root route. Verify expo-router behavior: if `(tabs)` is a group, `app/index.tsx` may conflict. Remove `app/index.tsx` if `(tabs)/index.tsx` handles the root route.

    **types.ts -- Expand AG-UI event types and add streaming callbacks:**

    1. Add new event types to `AGUIEventType`:
       ```typescript
       export type AGUIEventType =
         | "message"
         | "RUN_STARTED"
         | "TEXT_MESSAGE_START"
         | "TEXT_MESSAGE_CONTENT"
         | "TEXT_MESSAGE_END"
         | "STEP_STARTED"
         | "STEP_FINISHED"
         | "TOOL_CALL_START"
         | "TOOL_CALL_END"
         | "CUSTOM"
         | "RUN_FINISHED"
         | "RUN_ERROR";
       ```

    2. Add `StreamingCallbacks` interface:
       ```typescript
       export interface StreamingCallbacks {
         onStepStart?: (stepName: string) => void;
         onStepFinish?: (stepName: string) => void;
         onTextDelta?: (delta: string) => void;
         onHITLRequired?: (threadId: string, questionText: string) => void;
         onComplete: (result: string) => void;
         onError: (error: string) => void;
       }
       ```

    3. Update `SendCaptureOptions` to use `StreamingCallbacks`:
       ```typescript
       export interface SendCaptureOptions {
         message: string;
         apiKey: string;
         callbacks: StreamingCallbacks;
       }
       ```

    4. Add `SendClarificationOptions` interface:
       ```typescript
       export interface SendClarificationOptions {
         threadId: string;
         bucket: string;
         apiKey: string;
         callbacks: StreamingCallbacks;
       }
       ```

    **ag-ui-client.ts -- Update with streaming callbacks and sendClarification:**

    1. Refactor `sendCapture` to use `StreamingCallbacks`:
       - Replace `onComplete` and `onError` params with `callbacks` object.
       - Add event handlers for STEP_STARTED, STEP_FINISHED, TOOL_CALL_START, TOOL_CALL_END (call corresponding callbacks).
       - On CUSTOM event with name "HITL_REQUIRED": call `callbacks.onHITLRequired?.(value.threadId, accumulated_result)`. The accumulated result IS the clarifying question text.
       - On TEXT_MESSAGE_CONTENT: append to result AND call `callbacks.onTextDelta?.(parsed.delta)`.
       - On RUN_FINISHED: call `callbacks.onComplete(result)`.
       - On error: call `callbacks.onError(errorMessage)`.
       - Store the thread_id used in the request body so it can be referenced later.
       - Return both the cleanup function AND the thread_id: `return { cleanup, threadId }` (change return type).

    2. Add `sendClarification` function:
       ```typescript
       export function sendClarification({
         threadId,
         bucket,
         apiKey,
         callbacks,
       }: SendClarificationOptions): () => void
       ```
       - POST to `${API_BASE_URL}/api/ag-ui/respond` with body `{ thread_id: threadId, response: bucket }`.
       - The `response` field contains the bucket name the user selected (e.g., "People").
       - Listen for TEXT_MESSAGE_CONTENT and RUN_FINISHED events same as sendCapture.
       - Return cleanup function.
  </action>
  <verify>
    Verify TypeScript compiles without errors:
    ```bash
    cd mobile && npx tsc --noEmit 2>&1 | head -50
    ```
    If TypeScript checker is not configured, verify the files are syntactically correct by checking for common issues.
    Verify expo-router can resolve the tab layout:
    ```bash
    ls mobile/app/(tabs)/_layout.tsx && ls mobile/app/(tabs)/index.tsx && echo "Tab files exist"
    ```
  </verify>
  <done>
    Tab navigation with Capture and Inbox tabs is set up. Types include STEP_STARTED, STEP_FINISHED, CUSTOM events and StreamingCallbacks. SSE client dispatches all streaming events to callbacks and supports sendClarification for HITL bucket selection. App opens to Capture tab by default with all 4 capture buttons preserved.
  </done>
</task>

<task type="auto">
  <name>Task 2: Capture screen with step dots, streaming text, and inline HITL bucket buttons</name>
  <files>
    mobile/components/AgentSteps.tsx
    mobile/app/capture/text.tsx
  </files>
  <action>
    **AgentSteps.tsx -- New step indicator component (per locked decisions):**

    1. Create `mobile/components/AgentSteps.tsx` with the progress stepper pattern.
    2. Props:
       ```typescript
       interface AgentStepsProps {
         steps: string[];           // ["Orchestrator", "Classifier"]
         currentStep: string | null;
         completedSteps: string[];
       }
       ```
    3. Render horizontal row of pill-shaped indicators:
       - Each step is a rounded pill (not a circle dot) per locked decision "step dots (horizontal pills)".
       - Default state: dim/gray pill with step name below.
       - Active state: pulsing/highlighted pill (use a brighter color, e.g., `#4a90d9` blue). Can use a simple opacity animation or just a solid bright color (no reanimated needed).
       - Completed state: green pill (`#4ade80`).
       - Steps connected by a thin line/dash between pills.
       - Overall layout: horizontal, centered, compact.
    4. Style with dark theme colors matching the app (`#0f0f23` background context, `#1a1a2e` surface).

    **text.tsx -- Major update for real-time streaming and HITL:**

    1. **State additions:**
       ```typescript
       const [currentStep, setCurrentStep] = useState<string | null>(null);
       const [completedSteps, setCompletedSteps] = useState<string[]>([]);
       const [streamedText, setStreamedText] = useState("");
       const [showSteps, setShowSteps] = useState(false);
       const [hitlQuestion, setHitlQuestion] = useState<string | null>(null);
       const [hitlThreadId, setHitlThreadId] = useState<string | null>(null);
       const [isResolving, setIsResolving] = useState(false);
       ```

    2. **Update handleSubmit** to use StreamingCallbacks:
       ```typescript
       const captureResult = sendCapture({
         message: thought.trim(),
         apiKey: API_KEY,
         callbacks: {
           onStepStart: (stepName) => {
             setShowSteps(true);
             setCurrentStep(stepName);
           },
           onStepFinish: (stepName) => {
             setCompletedSteps((prev) => [...prev, stepName]);
             setCurrentStep(null);
           },
           onTextDelta: (delta) => {
             setStreamedText((prev) => prev + delta);
           },
           onHITLRequired: (threadId, questionText) => {
             setHitlThreadId(threadId);
             setHitlQuestion(questionText);
             setSending(false); // Re-enable interaction for bucket selection
           },
           onComplete: (result) => {
             setSending(false);
             Haptics.notificationAsync(Haptics.NotificationFeedbackType.Success);
             setToast({ message: result || "Captured", type: "success" });
             // Auto-reset after 2.5 seconds per locked decision (2-3 sec range)
             setTimeout(() => {
               setThought("");
               setShowSteps(false);
               setCurrentStep(null);
               setCompletedSteps([]);
               setStreamedText("");
               setHitlQuestion(null);
               setHitlThreadId(null);
             }, 2500);
           },
           onError: (error) => {
             void error;
             setSending(false);
             setShowSteps(false);
             setToast({ message: "Couldn\u2019t file your capture. Try again.", type: "error" });
           },
         },
       });
       cleanupRef.current = captureResult.cleanup;
       ```

    3. **Add bucket button handler:**
       ```typescript
       const handleBucketSelect = (bucket: string) => {
         if (!hitlThreadId || isResolving) return;
         setIsResolving(true);
         setHitlQuestion(null); // Hide question UI
         const cleanup = sendClarification({
           threadId: hitlThreadId,
           bucket,
           apiKey: API_KEY!,
           callbacks: {
             onTextDelta: (delta) => setStreamedText((prev) => prev + delta),
             onComplete: (result) => {
               setIsResolving(false);
               Haptics.notificationAsync(Haptics.NotificationFeedbackType.Success);
               setToast({ message: result || "Filed", type: "success" });
               setTimeout(() => {
                 // Full reset
                 setThought("");
                 setShowSteps(false);
                 setCurrentStep(null);
                 setCompletedSteps([]);
                 setStreamedText("");
                 setHitlQuestion(null);
                 setHitlThreadId(null);
               }, 2500);
             },
             onError: () => {
               setIsResolving(false);
               setToast({ message: "Couldn\u2019t file. Try again.", type: "error" });
             },
           },
         });
         cleanupRef.current = cleanup;
       };
       ```

    4. **Layout below the TextInput** (per locked decisions: step dots appear BELOW text input):
       - When `showSteps` is true: render `<AgentSteps>` component below the TextInput.
       - When `streamedText` is non-empty: render streaming text below the step dots (word-by-word ChatGPT effect). Use a `<Text>` element that updates as deltas arrive.
       - When `hitlQuestion` is non-null: render the question text ABOVE 4 bucket buttons:
         ```
         [Question text from agent]
         [People] [Projects] [Ideas] [Admin]
         ```
       - Bucket buttons: 4 horizontal buttons with just the bucket name (no confidence scores per locked decision). Styled as tappable pills/buttons.
       - Tapping a bucket button calls `handleBucketSelect(bucket)` and files immediately (no confirmation per locked decision).

    5. **Handle ignored clarification** per locked decision: If user submits a new capture while HITL is pending, the pending item stays in inbox. Reset HITL state and allow new capture:
       - In handleSubmit: if `hitlThreadId` is set, clear it (the backend session stays in _pending_sessions until TTL cleanup or manual resolution from inbox).

    6. **Visual polish:**
       - Step dots area has subtle background or separator from the text input.
       - Streaming text uses same font as input but slightly smaller, in a muted color.
       - Bucket buttons use distinct colors per bucket or a uniform style (Claude's discretion).
       - During `isResolving`, show a subtle loading indicator on the selected bucket button.
  </action>
  <verify>
    Verify TypeScript compiles:
    ```bash
    cd mobile && npx tsc --noEmit 2>&1 | head -50
    ```
    Verify AgentSteps component exists:
    ```bash
    ls mobile/components/AgentSteps.tsx && echo "AgentSteps OK"
    ```
    Verify text.tsx has the new state variables and AgentSteps import:
    ```bash
    grep -l "AgentSteps\|hitlQuestion\|sendClarification" mobile/app/capture/text.tsx && echo "text.tsx updated"
    ```
  </verify>
  <done>
    Text capture screen shows step dots lighting up sequentially as Orchestrator and Classifier process. Streamed text appears word-by-word below step dots. Low-confidence classifications show agent's question with 4 bucket buttons (People / Projects / Ideas / Admin) for quick resolution. Tapping a bucket files immediately. Auto-reset after 2.5 seconds on successful classification. New captures can be submitted while HITL is pending (pending item stays in inbox).
  </done>
</task>

</tasks>

<verification>
1. App opens to Capture tab with 4 capture buttons and Inbox tab in bottom bar
2. Tapping Text opens capture screen with text input
3. Submitting text shows step dots lighting up (Orchestrator, then Classifier)
4. Streamed text appears word-by-word below step dots
5. After classification, result shows in toast and auto-resets after ~2.5 seconds
6. TypeScript compiles without errors
7. No regressions in existing functionality
</verification>

<success_criteria>
Will sees real-time agent chain progression via step dots and streaming text on the capture screen. Low-confidence classifications show inline clarification with 4 bucket buttons. Tab navigation provides one-tap access to Capture and Inbox. All per locked CONTEXT.md decisions.
</success_criteria>

<output>
After completion, create `.planning/phases/04-hitl-clarification-and-ag-ui-streaming/04-02-SUMMARY.md`
</output>
