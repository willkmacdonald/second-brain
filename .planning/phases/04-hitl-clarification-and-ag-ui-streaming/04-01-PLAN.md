---
phase: 04-hitl-clarification-and-ag-ui-streaming
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/src/second_brain/agents/workflow.py
  - backend/src/second_brain/agents/classifier.py
  - backend/src/second_brain/api/inbox.py
  - backend/src/second_brain/main.py
autonomous: true
requirements: [CLAS-04, CAPT-02, APPX-02]

must_haves:
  truths:
    - "AG-UI SSE stream emits StepStarted and StepFinished events when agents change during workflow execution"
    - "When classification confidence is below 0.6, the Classifier's clarifying question is streamed to the client as TEXT_MESSAGE_CONTENT events followed by a CUSTOM HITL_REQUIRED event"
    - "POST /api/ag-ui/respond resumes a paused HITL workflow and streams the result back via SSE"
    - "GET /api/inbox returns recent captures ordered by createdAt DESC with classification metadata"
    - "Orchestrator text is filtered from streamed response (echo bug fix)"
  artifacts:
    - path: "backend/src/second_brain/agents/workflow.py"
      provides: "AGUIWorkflowAdapter with HITL support, step events, echo filtering, respond endpoint"
      contains: "_pending_sessions"
    - path: "backend/src/second_brain/agents/classifier.py"
      provides: "Updated Classifier instructions for clarification questions and bucket button resolution"
      contains: "clarifying question"
    - path: "backend/src/second_brain/api/inbox.py"
      provides: "GET /api/inbox REST endpoint querying Cosmos DB Inbox container"
      contains: "list_inbox"
    - path: "backend/src/second_brain/main.py"
      provides: "Respond endpoint registration and inbox router inclusion"
      contains: "inbox"
  key_links:
    - from: "backend/src/second_brain/agents/workflow.py"
      to: "agent_framework.orchestrations.HandoffAgentUserRequest"
      via: "request_info event handling"
      pattern: "HandoffAgentUserRequest"
    - from: "backend/src/second_brain/main.py"
      to: "backend/src/second_brain/api/inbox.py"
      via: "FastAPI router include"
      pattern: "include_router.*inbox"
---

<objective>
Backend HITL workflow, AG-UI step events, echo filter, respond endpoint, and Inbox API

Purpose: Enable the backend to (1) stream real-time agent step transitions to the mobile client, (2) pause the workflow when the Classifier needs clarification and resume it when the user responds, (3) filter the Orchestrator echo from streamed text, and (4) serve Inbox listing data.

Output: Updated workflow.py with HITL + step events + echo filter, updated classifier.py with clarification instructions, new api/inbox.py REST endpoint, updated main.py with respond endpoint and inbox router.
</objective>

<execution_context>
@/Users/willmacdonald/.claude/get-shit-done/workflows/execute-plan.md
@/Users/willmacdonald/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-hitl-clarification-and-ag-ui-streaming/04-CONTEXT.md
@.planning/phases/04-hitl-clarification-and-ag-ui-streaming/04-RESEARCH.md
@.planning/phases/03-text-classification-pipeline/03-01-SUMMARY.md

# Key source files to read before implementing:
@backend/src/second_brain/agents/workflow.py
@backend/src/second_brain/agents/classifier.py
@backend/src/second_brain/tools/classification.py
@backend/src/second_brain/main.py
@backend/src/second_brain/models/documents.py
@backend/src/second_brain/api/health.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: HITL workflow + step events + echo filter in AGUIWorkflowAdapter</name>
  <files>
    backend/src/second_brain/agents/workflow.py
    backend/src/second_brain/agents/classifier.py
  </files>
  <action>
    **workflow.py -- Major refactor of AGUIWorkflowAdapter:**

    1. **Import additions:** Add `HandoffAgentUserRequest` from `agent_framework.orchestrations`, `StepStartedEvent` and `StepFinishedEvent` from `ag_ui.core.events` (or construct manually if not available -- check installed packages first). Also import `EventType` from `ag_ui.core`.

    2. **Add `_pending_sessions` class variable:** `_pending_sessions: dict[str, tuple] = {}` as a class-level dict to store pending HITL sessions keyed by thread_id. Each value is a tuple of `(workflow_instance, request_id)`.

    3. **Change `_create_workflow_agent` to `_create_workflow`:** Return the raw `Workflow` object (from `HandoffBuilder.build()`), NOT wrapped in `WorkflowAgent`. This is required because `WorkflowAgent` doesn't expose `run(responses=...)` for resuming HITL sessions. Keep `WorkflowAgent` only for the converter function reference.

    4. **Update `with_autonomous_mode`:** Change from `agents=[self._orchestrator, self._classifier]` to `agents=[self._orchestrator]` only. Remove the Classifier from autonomous mode so it can emit `request_info` events when it responds without handing off. Remove the Classifier's autonomous prompt. Keep the Orchestrator's prompt: `"Route this input to the Classifier."`.

    5. **Refactor `_stream_updates` for HITL support:**
       - Accept `thread_id` as a parameter (extract from kwargs or generate UUID).
       - Track `current_agent` (str or None) for step event emission.
       - Track `user_input_text` (extracted from messages) for echo filtering.
       - Use `workflow.run_stream(messages)` (raw workflow, not WorkflowAgent).
       - On `WorkflowEvent` with type `"executor_invoked"`: emit `StepStartedEvent(step_name=event.executor_id)` as an `AgentResponseUpdate`.
       - On `WorkflowEvent` with type `"executor_completed"`: emit `StepFinishedEvent(step_name=event.executor_id)` as an `AgentResponseUpdate`.
       - On `WorkflowEvent` with type `"request_info"` and `isinstance(event.data, HandoffAgentUserRequest)`: store `(workflow, event.request_id)` in `_pending_sessions[thread_id]`. Emit the agent's clarifying question text from `event.data.agent_response.messages` as TEXT_MESSAGE_CONTENT-style updates. Then emit a custom event dict `{"type": "CUSTOM", "name": "HITL_REQUIRED", "value": {"threadId": thread_id}}` and return (end stream).
       - For `AgentResponseUpdate` events: filter echo by checking if the event is from the Orchestrator agent (use `current_agent` tracking). Skip text updates from the Orchestrator agent entirely -- only yield text from the Classifier.
       - For other `WorkflowEvent` types: use the existing converter pattern to convert to `AgentResponseUpdate`.
       - At stream end, emit final `StepFinishedEvent` for `current_agent` if set.

    6. **Add `resume_with_response` method:**
       ```python
       async def resume_with_response(self, thread_id: str, user_response: str) -> AsyncIterable[AgentResponseUpdate]:
       ```
       - Pop `(workflow, request_id)` from `_pending_sessions[thread_id]`.
       - Raise `ValueError` if thread_id not found.
       - Create response: `responses = {request_id: HandoffAgentUserRequest.create_response(user_response)}`
       - Call `workflow.run(responses=responses, stream=True)` and iterate over events, converting and yielding same as `_stream_updates`.
       - Track `current_agent` for step events same as in `_stream_updates`.

    7. **Add `respond_stream` public method** that wraps `resume_with_response` in a `ResponseStream` (same pattern as the `run` method wraps `_stream_updates`).

    8. **Update `run` method:** Pass `thread_id` from kwargs through to `_stream_updates`. Extract it from the incoming AG-UI request's `thread_id` field.

    **IMPORTANT NOTES:**
    - The AG-UI endpoint framework calls `agent.run(messages, stream=True, thread=thread)`. The `thread.id` should be used as `thread_id`.
    - For StepStarted/StepFinished events: if AG-UI event classes (`StepStartedEvent`, `StepFinishedEvent`) are not easily importable or don't convert to `AgentResponseUpdate`, emit them as raw dicts that will serialize to SSE correctly. Check how the AG-UI adapter serializes events to SSE -- it may need specific event class instances. If the converter doesn't handle them, emit them as custom dict updates that the SSE serializer can handle.
    - DO NOT import from private/internal modules if public API exists. Check `ag_ui.core` package first.

    **classifier.py -- Update instructions for HITL:**

    1. Add low-confidence handling instructions AFTER the existing rules section:
       ```
       ## Low Confidence Handling

       When the classify_and_file tool returns a message starting with "Filed" AND the
       confidence score you used was below 0.6:
       1. Ask the user ONE focused clarifying question to help distinguish between the
          top 2 likely buckets
       2. Present the question concisely (one sentence)
       3. Wait for the user's response
       4. After receiving clarification, call classify_and_file again with the
          user-specified bucket and higher confidence (0.80+)

       When the user responds with just a bucket name (People, Projects, Ideas, or Admin):
       - Call classify_and_file immediately with that bucket at confidence 0.85
       - The user is overriding your classification -- honor their choice

       You may ask at most 2 clarifying questions. If still uncertain after 2 exchanges,
       file with your best guess at confidence 0.55.
       ```

    2. Update Rule 1 to NOT require always calling a tool immediately -- the Classifier should be able to ask a question first when confidence is low:
       ```
       1. When confidence >= 0.6, ALWAYS call classify_and_file immediately
       2. When confidence < 0.6, ask ONE clarifying question first, then file after
          receiving the response
       3. NEVER respond without eventually calling classify_and_file or mark_as_junk
       ```

    3. Update Rule 4: Remove "Do NOT add any extra commentary before or after the confirmation" -- the Classifier needs to generate clarifying questions.
  </action>
  <verify>
    Run existing tests to check for regressions:
    ```bash
    cd backend && python -m pytest tests/ -v
    ```
    All 31 existing tests should pass. Import the updated modules to verify no import errors:
    ```bash
    cd backend && python -c "from second_brain.agents.workflow import AGUIWorkflowAdapter; print('workflow OK')"
    cd backend && python -c "from second_brain.agents.classifier import create_classifier_agent; print('classifier OK')"
    ```
  </verify>
  <done>
    AGUIWorkflowAdapter emits StepStarted/StepFinished events on agent transitions, handles request_info by storing pending session and streaming clarifying question, supports resume_with_response for HITL continuation, filters Orchestrator echo from streamed text. Classifier instructions include low-confidence clarification flow and bucket button override handling. All existing tests pass.
  </done>
</task>

<task type="auto">
  <name>Task 2: Inbox API endpoint and respond endpoint wiring in main.py</name>
  <files>
    backend/src/second_brain/api/inbox.py
    backend/src/second_brain/main.py
  </files>
  <action>
    **api/inbox.py -- New REST endpoint for Inbox listing:**

    1. Create `backend/src/second_brain/api/inbox.py` modeled on `api/health.py` pattern.

    2. Define response models:
       ```python
       class InboxItemResponse(BaseModel):
           id: str
           rawText: str
           title: str | None
           status: str
           createdAt: str
           classificationMeta: dict | None

       class InboxListResponse(BaseModel):
           items: list[InboxItemResponse]
           count: int
       ```
       Use camelCase field names per project convention (Ruff N815 ignore if needed).

    3. Implement `GET /api/inbox`:
       ```python
       @router.get("/api/inbox", response_model=InboxListResponse)
       async def list_inbox(request: Request, limit: int = 20, offset: int = 0) -> InboxListResponse:
       ```
       - Access `request.app.state.cosmos_manager` to get Cosmos DB.
       - Query: `SELECT * FROM c WHERE c.userId = @userId ORDER BY c.createdAt DESC OFFSET @offset LIMIT @limit`
       - Parameters: `[{"name": "@userId", "value": "will"}, {"name": "@limit", "value": limit}, {"name": "@offset", "value": offset}]`
       - Use `partition_key="will"` for efficient partition-scoped query.
       - Return 503 if `cosmos_manager` is None (Cosmos not configured).

    4. Implement `GET /api/inbox/{item_id}` for detail view:
       ```python
       @router.get("/api/inbox/{item_id}")
       async def get_inbox_item(request: Request, item_id: str) -> dict:
       ```
       - Read single item by id from Inbox container.
       - Return 404 if not found.

    **main.py -- Wire respond endpoint and inbox router:**

    1. Import `inbox_router` from `second_brain.api.inbox`.

    2. Include inbox router: `app.include_router(inbox_router)`.

    3. Add the inbox API paths to `PUBLIC_PATHS` in auth.py if needed. Actually, inbox should be authenticated. Leave it behind the API key middleware (which is already applied globally). No change to auth.

    4. Add `/api/ag-ui/respond` POST endpoint directly in main.py (since it needs access to `workflow_agent` created in lifespan):
       ```python
       @app.post("/api/ag-ui/respond")
       async def respond_to_hitl(request: Request):
       ```
       - Parse request body for `thread_id` and `response`.
       - Access the `workflow_agent` (AGUIWorkflowAdapter) from `app.state`.
       - Call `workflow_agent.respond_stream(thread_id, response)`.
       - Return SSE `StreamingResponse` with the events.
       - Store `workflow_agent` on `app.state` in lifespan so the respond endpoint can access it.

    5. Update lifespan to store `workflow_agent` on `app.state`:
       ```python
       app.state.workflow_agent = workflow_agent
       ```

    6. The respond endpoint returns an SSE StreamingResponse. Use the same SSE serialization pattern that `add_agent_framework_fastapi_endpoint` uses. Check how the AG-UI library creates SSE responses and replicate that for the respond endpoint. If there's a helper function, use it. Otherwise, manually serialize events to `data: {json}\n\n` SSE format.
  </action>
  <verify>
    Run all tests:
    ```bash
    cd backend && python -m pytest tests/ -v
    ```
    Verify imports:
    ```bash
    cd backend && python -c "from second_brain.api.inbox import router; print('inbox router OK')"
    cd backend && python -c "from second_brain.main import app; print('main OK')"
    ```
    Verify the respond endpoint is registered:
    ```bash
    cd backend && python -c "
    from second_brain.main import app
    routes = [r.path for r in app.routes]
    assert '/api/inbox' in routes or any('/inbox' in r for r in routes), f'inbox not found in {routes}'
    print('Routes:', routes)
    "
    ```
  </verify>
  <done>
    GET /api/inbox returns paginated Inbox items with classification metadata ordered by createdAt DESC. GET /api/inbox/{item_id} returns a single item detail. POST /api/ag-ui/respond accepts thread_id and response, resumes the paused HITL workflow, and returns SSE stream with classification result. All endpoints are behind API key auth. All tests pass.
  </done>
</task>

</tasks>

<verification>
1. All 31+ existing backend tests pass with no regressions
2. workflow.py AGUIWorkflowAdapter has _pending_sessions dict, emits StepStarted/StepFinished, handles request_info, supports resume_with_response
3. classifier.py includes low-confidence clarification instructions and bucket override handling
4. api/inbox.py has list_inbox and get_inbox_item endpoints
5. main.py includes inbox router and has /api/ag-ui/respond endpoint
6. Server starts without errors: `cd backend && python -c "from second_brain.main import app; print('OK')"`
</verification>

<success_criteria>
Backend fully supports: (1) AG-UI step event emission for agent chain visibility, (2) HITL pause/resume via request_info and respond endpoint, (3) echo filtering for clean text streaming, (4) Inbox listing API for mobile consumption. All existing tests pass.
</success_criteria>

<output>
After completion, create `.planning/phases/04-hitl-clarification-and-ag-ui-streaming/04-01-SUMMARY.md`
</output>
