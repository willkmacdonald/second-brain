---
phase: 05-voice-capture
plan: 02
type: execute
wave: 2
depends_on:
  - 05-01
files_modified:
  - backend/src/second_brain/main.py
  - backend/src/second_brain/agents/orchestrator.py
autonomous: true
requirements:
  - ORCH-03
  - CAPT-04

must_haves:
  truths:
    - "POST /api/voice-capture accepts multipart audio upload and returns SSE stream"
    - "SSE stream includes Perception step (transcribing) then Orchestrator and Classifier steps"
    - "Audio is uploaded to Blob Storage, transcribed via Whisper, then classified through existing pipeline"
    - "Audio blob is deleted after successful transcription (no permanent storage per CONTEXT.md)"
    - "Orchestrator instructions updated to handle both text and audio-sourced input"
  artifacts:
    - path: "backend/src/second_brain/main.py"
      provides: "POST /api/voice-capture endpoint with multipart + SSE"
      contains: "voice_capture"
    - path: "backend/src/second_brain/agents/orchestrator.py"
      provides: "Updated orchestrator instructions mentioning audio routing"
      contains: "Perception"
  key_links:
    - from: "backend/src/second_brain/main.py"
      to: "backend/src/second_brain/db/blob_storage.py"
      via: "blob_manager.upload_audio() call in voice_capture endpoint"
      pattern: "upload_audio"
    - from: "backend/src/second_brain/main.py"
      to: "backend/src/second_brain/tools/transcription.py"
      via: "transcribe_audio() call in voice_capture endpoint"
      pattern: "transcribe_audio"
    - from: "backend/src/second_brain/main.py"
      to: "backend/src/second_brain/agents/workflow.py"
      via: "workflow_agent.run() for classification after transcription"
      pattern: "workflow_agent.run"
---

<objective>
Wire the voice-capture endpoint that accepts audio uploads, transcribes via Whisper, and routes the transcribed text through the existing classification pipeline with SSE streaming.

Purpose: This is the backend entry point for voice captures. The endpoint combines the infrastructure from Plan 01 (blob storage, transcription) with the existing workflow adapter (orchestrator + classifier) to produce a complete voice-to-classification pipeline.

Output: Working POST /api/voice-capture endpoint, updated Orchestrator instructions.
</objective>

<execution_context>
@/Users/willmacdonald/.claude/get-shit-done/workflows/execute-plan.md
@/Users/willmacdonald/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-voice-capture/05-RESEARCH.md
@.planning/phases/05-voice-capture/05-CONTEXT.md
@.planning/phases/05-voice-capture/05-01-SUMMARY.md
@backend/src/second_brain/main.py
@backend/src/second_brain/agents/orchestrator.py
@backend/src/second_brain/agents/workflow.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create POST /api/voice-capture endpoint with multipart upload + SSE streaming</name>
  <files>
    backend/src/second_brain/main.py
  </files>
  <action>
**main.py** -- Add the voice-capture endpoint and BlobStorageManager lifecycle:

**1. Imports** -- Add at the appropriate noqa: E402 section:
- `from fastapi import File, UploadFile` (add File and UploadFile to existing FastAPI import)
- `import asyncio` (for asyncio.to_thread)
- `from second_brain.db.blob_storage import BlobStorageManager`
- `from second_brain.tools.transcription import transcribe_audio`
- `from ag_ui.core.events import StepStartedEvent, StepFinishedEvent` (already imported, verify)

**2. Lifespan** -- Initialize BlobStorageManager:
- After Cosmos DB initialization block, add BlobStorageManager initialization:
  ```python
  blob_manager: BlobStorageManager | None = None
  if settings.blob_storage_url:
      blob_mgr = BlobStorageManager(account_url=settings.blob_storage_url)
      try:
          await blob_mgr.initialize()
          blob_manager = blob_mgr
          app.state.blob_manager = blob_manager
          logger.info("Blob Storage manager initialized")
      except Exception:
          logger.warning("Could not initialize Blob Storage. Voice capture will not be available.")
          app.state.blob_manager = None
  else:
      app.state.blob_manager = None
  ```
- In cleanup section: `if app.state.blob_manager: await app.state.blob_manager.close()`

**3. Voice-capture endpoint** -- New `@app.post("/api/voice-capture")`:
```python
@app.post("/api/voice-capture", tags=["Capture"])
async def voice_capture(
    request: Request,
    file: UploadFile = File(...),
) -> StreamingResponse:
```

The endpoint flow:
1. Read audio bytes from UploadFile: `audio_bytes = await file.read()`
2. Guard: check file size > 0 and <= 25MB (Whisper limit). If too small (< 1024 bytes), return error "Recording too short".
3. Get blob_manager and settings from app.state
4. Generate thread_id and run_id
5. Return StreamingResponse with SSE generator

The SSE generator:
1. Yield RunStartedEvent
2. **Perception step** (synthetic -- not via agent framework):
   - Yield StepStartedEvent(step_name="Perception")
   - Upload audio to Blob Storage: `blob_url = await blob_manager.upload_audio(audio_bytes, file.filename or "voice-capture.m4a")`
   - Transcribe: `transcription = await asyncio.to_thread(transcribe_audio, audio_bytes, file.filename or "voice-capture.m4a", settings.azure_openai_whisper_deployment_name, settings.azure_openai_endpoint)`
   - Delete blob after transcription: `await blob_manager.delete_audio(blob_url)` (per CONTEXT.md: "Delete voice recordings after successful transcription")
   - Yield StepFinishedEvent(step_name="Perception")
3. **Classification pipeline** -- Feed transcribed text through existing workflow:
   - `from agent_framework import Message as AFMessage`
   - Create messages: `[AFMessage(role="user", text=transcription)]`
   - Run workflow: `stream = workflow_agent.run(messages, stream=True, thread=thread, thread_id=thread_id)`
   - Iterate the stream using the same _stream_sse helper pattern (convert StreamItems to SSE events)
   - The existing workflow adapter handles Orchestrator -> Classifier step events and outcome detection
4. Yield RunFinishedEvent

Error handling:
- If blob_manager is None: yield error text message "Voice capture not available (Blob Storage not configured)"
- If transcription fails: yield error text message "Transcription failed. Please try again."
- If transcription is empty: yield error text message "Could not transcribe audio. Please try again."
- On any error: ensure StepFinished is yielded if StepStarted was yielded (clean state)
- Wrap Whisper call in try/except -- on failure, still clean up (delete blob if uploaded)

Add `/api/voice-capture` to the PUBLIC_PATHS... actually NO -- it requires auth. The APIKeyMiddleware should already apply since it's not in the public paths list. Verify the auth middleware passes the Authorization header through for multipart requests.

IMPORTANT per CONTEXT.md decision: "Send immediately on stop -- no preview/playback step before sending". The endpoint should be fast. No preview or confirmation -- just process and stream.
  </action>
  <verify>
- `ruff check backend/src/second_brain/main.py` passes
- `ruff format --check backend/src/second_brain/main.py` passes
- `cd backend && python3 -m pytest tests/ -x` -- all existing tests pass
- `python3 -c "from second_brain.main import app; routes = [r.path for r in app.routes]; assert '/api/voice-capture' in routes; print('voice-capture endpoint registered')"` confirms endpoint exists
  </verify>
  <done>
POST /api/voice-capture endpoint accepts multipart audio upload, uploads to Blob Storage, transcribes via Whisper, deletes audio blob, feeds transcribed text through classification pipeline, and streams SSE events with Perception + Orchestrator + Classifier step progression.
  </done>
</task>

<task type="auto">
  <name>Task 2: Update Orchestrator instructions for audio-sourced input routing</name>
  <files>
    backend/src/second_brain/agents/orchestrator.py
  </files>
  <action>
**agents/orchestrator.py** -- Update the Orchestrator instructions:

The Orchestrator receives text input that may have been transcribed from audio by the Perception Agent. The instructions should mention that input may come from voice transcription, but the routing behavior is the same: always hand off to the Classifier.

Update the instructions string to:
```
"You are the Orchestrator for a personal knowledge management system. "
"Your ONLY job is to route user input to the correct specialist agent. "
"NEVER answer questions directly. ALWAYS hand off to a specialist.\n\n"
"Input may be typed text or transcribed speech from the Perception Agent. "
"In both cases: hand off to the Classifier agent immediately.\n\n"
"Do not add commentary. Just hand off."
```

This is a minimal change -- the routing logic doesn't change, but the instructions acknowledge the Perception Agent exists in the pipeline. This fulfills ORCH-03 (Orchestrator routes audio input through the pipeline).

NOTE: The Orchestrator does NOT hand off to the Perception Agent. The Perception step (transcription) happens BEFORE the workflow runs. By the time the Orchestrator sees the input, it's already text. This is by design -- Whisper needs raw audio bytes, which can't flow through the text-based agent framework.
  </action>
  <verify>
- `ruff check backend/src/second_brain/agents/orchestrator.py` passes
- `python3 -c "from second_brain.agents.orchestrator import create_orchestrator_agent; print('OK')"` imports
- `grep -q 'Perception' backend/src/second_brain/agents/orchestrator.py` confirms Perception is mentioned
  </verify>
  <done>
Orchestrator instructions updated to acknowledge audio-sourced input from the Perception Agent while maintaining the same routing behavior (always hand off to Classifier).
  </done>
</task>

</tasks>

<verification>
1. `ruff check backend/src/second_brain/main.py backend/src/second_brain/agents/orchestrator.py` passes
2. POST /api/voice-capture endpoint is registered on the app
3. Existing tests pass: `cd backend && python3 -m pytest tests/ -x`
4. Orchestrator instructions mention Perception Agent
5. Voice-capture endpoint handles: upload -> transcribe -> classify -> SSE stream
</verification>

<success_criteria>
- POST /api/voice-capture accepts multipart form data with audio file
- SSE stream includes synthetic Perception step + workflow Orchestrator/Classifier steps
- Audio uploaded to Blob Storage, transcribed, blob deleted, text classified
- Error handling for missing blob manager, transcription failure, empty transcription
- Orchestrator instructions updated for audio routing awareness
- All existing tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/05-voice-capture/05-02-SUMMARY.md`
</output>
