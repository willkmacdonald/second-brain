---
phase: 04.3-agent-user-ux-with-unclear-item
plan: 05
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/src/second_brain/agents/workflow.py
autonomous: true
requirements: [CLAS-04, APPX-04]
gap_closure: true

must_haves:
  truths:
    - "High-confidence capture streams only the tool result text (e.g., 'Filed -> Admin (0.90)'), not classifier chain-of-thought reasoning"
    - "Low-confidence capture streams only the tool result text (e.g., 'Filed (needs review) -> People (0.55)'), not verbose reasoning"
    - "Misunderstood capture emits MISUNDERSTOOD event so capture screen enters conversation mode"
  artifacts:
    - path: "backend/src/second_brain/agents/workflow.py"
      provides: "Classifier text filter and function_call-based misunderstood detection"
      contains: "_is_classifier_reasoning"
  key_links:
    - from: "backend/src/second_brain/agents/workflow.py"
      to: "mobile/app/capture/text.tsx"
      via: "SSE stream: only tool result text reaches onTextDelta, MISUNDERSTOOD event reaches onMisunderstood"
      pattern: "CustomEvent.*MISUNDERSTOOD"
---

<objective>
Fix two backend streaming issues diagnosed in UAT: (1) Classifier chain-of-thought reasoning text leaks through the echo filter to the client, and (2) MISUNDERSTOOD event is never emitted because regex-based detection of tool output in streamed text fails (tool results are consumed internally by the LLM, not present in update.text).

Purpose: UAT Tests 1, 2, and 3 all fail due to these backend streaming issues. Fixing them unblocks the entire capture screen UX -- auto-reset, clean toast, and conversation mode.
Output: Updated workflow.py with proper Classifier text filtering and reliable misunderstood detection.
</objective>

<execution_context>
@/Users/willmacdonald/.claude/get-shit-done/workflows/execute-plan.md
@/Users/willmacdonald/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04.3-agent-user-ux-with-unclear-item/04.3-01-SUMMARY.md
@.planning/phases/04.3-agent-user-ux-with-unclear-item/04.3-UAT.md
@backend/src/second_brain/agents/workflow.py
@backend/src/second_brain/agents/classifier.py
@backend/src/second_brain/tools/classification.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Filter Classifier reasoning text and detect misunderstood via function_call content</name>
  <files>backend/src/second_brain/agents/workflow.py</files>
  <action>
Two changes to `_stream_updates` in AGUIWorkflowAdapter:

**Change 1: Suppress Classifier chain-of-thought text, only yield tool result lines.**

The current echo filter (`_is_orchestrator_text`) only suppresses Orchestrator text. Classifier reasoning tokens (chain-of-thought before the tool call) pass through to the client as TEXT_MESSAGE_CONTENT events, causing verbose scores breakdown to stream instead of just "Filed -> Admin (0.90)".

Add a new filter method `_is_classifier_reasoning` that checks:
- `update.author_name` matches "Classifier" (case-insensitive)
- The update contains ONLY text content (no function_call content)
- The text does NOT match any known tool result pattern

Known tool result patterns to ALLOW through (these are the only Classifier text that should reach the client):
- `_FILED_CONFIDENCE_RE`: matches "Filed -> Bucket (0.XX)"
- A new regex `_FILED_PENDING_RE = re.compile(r"Filed\s*\(needs review\)")`: matches "Filed (needs review) -> Bucket (0.XX)"
- `_MISUNDERSTOOD_RE`: matches "Misunderstood -> uuid | text"
- `_CLARIFICATION_RE`: matches "Clarification -> uuid | text"

In _stream_updates, after the `_is_orchestrator_text` check, add a check: if `_is_classifier_reasoning(update)` is True, log debug and `continue` (skip yielding). This means only tool result lines from the Classifier reach the client.

**IMPORTANT**: The text content from the Classifier comes in streaming deltas (small chunks). The tool result pattern won't match on individual deltas. Therefore, the filter needs to BUFFER Classifier text content. Approach:
- Maintain a `classifier_text_buffer: str = ""` variable in `_stream_updates`
- When an update from the Classifier contains only text content, APPEND to buffer instead of yielding immediately
- When `_FILED_CONFIDENCE_RE`, `_FILED_PENDING_RE`, or `_MISUNDERSTOOD_RE` matches the buffer, flush (yield) only the matching portion as a single AgentResponseUpdate
- When a non-text event arrives from the Classifier (e.g., function_call), or when the Classifier step finishes, discard the buffer (it was reasoning text)
- This avoids the complexity of trying to filter individual streaming deltas

Actually, a simpler approach: Since we want to suppress ALL Classifier text and only show the tool result, and the tool result patterns are detected via regex on the accumulated text ANYWAY for HITL/MISUNDERSTOOD detection -- just suppress ALL Classifier text updates entirely. The toast message on the client comes from `onComplete(result)` where `result` is the accumulated text. If we suppress Classifier text from streaming, the accumulated result will be empty, and the capture screen already falls back to "Captured" toast.

But wait -- the toast should show "Filed -> Admin (0.90)" or "Filed (needs review) -> People (0.55)". This comes from the accumulated `result` variable in `attachCallbacks`. If we suppress all Classifier text, the client gets no text content at all, and `result` will be empty.

**Better approach**: Buffer all Classifier text. At the end of the stream (or when a recognized tool result pattern is detected in the buffer), yield ONLY a single AgentResponseUpdate containing the clean tool result text. Discard everything else.

Implementation:
1. Add a `classifier_buffer: str = ""` variable in `_stream_updates`
2. For Classifier text-only updates: append `update.text` to `classifier_buffer` and do NOT yield
3. Keep existing detection logic that checks `update.text` for misunderstood/clarification/confidence patterns -- but operate on the buffer instead
4. After the stream loop ends (before emitting custom events), check `classifier_buffer` for tool result patterns. If a match is found, construct and yield a single `AgentResponseUpdate` with just the tool result text. Use the `_FILED_CONFIDENCE_RE` or `_FILED_PENDING_RE` match to extract just the "Filed -> Bucket (0.XX)" or "Filed (needs review) -> Bucket (0.XX)" line
5. For the specific detection: also run misunderstood/clarification/confidence extraction on the full buffer after each append, so detection still works during streaming

Concrete code changes:
- Add `_FILED_PENDING_RE = re.compile(r"Filed\s*\(needs review\)\s*→\s*\w+\s*\(\d+\.\d+\)")` near the other regexes
- Add `_TOOL_RESULT_RE = re.compile(r"(Filed\s*(?:\(needs review\)\s*)?→\s*\w+\s*\(\d+\.\d+\)|Misunderstood\s*→\s*[a-f0-9\-]+\s*\|.+|Clarification\s*→\s*[a-f0-9\-]+\s*\|.+)")` as a combined pattern
- Add `classifier_buffer = ""` in `_stream_updates`
- Create helper `_is_classifier_text(self, update: AgentResponseUpdate) -> bool` that returns True if author_name is Classifier and contents are all text type
- In both the WorkflowEvent converted updates loop and the direct AgentResponseUpdate branch: if `_is_classifier_text(update)`, append to buffer, run detection on buffer, and `continue` (don't yield)
- After the stream loop, before custom event emission: extract tool result from `classifier_buffer` using `_TOOL_RESULT_RE`. If found, yield a final AgentResponseUpdate with only that matched text. Construct it using `AgentResponseUpdate(author_name="Classifier", contents=[...])` -- check how existing updates are structured and replicate. Or simpler: keep one of the original updates (the last one) and replace its text content with just the tool result.

Actually, looking at AgentResponseUpdate more carefully -- it has a `text` property and `contents`. The simplest approach:
- Buffer all Classifier text into `classifier_buffer`
- After stream loop ends, if buffer contains a tool result match, yield a synthetic update. Check what fields AgentResponseUpdate needs. From the import: `from agent_framework import AgentResponseUpdate`. Look at how the converter creates them -- we can create a minimal one.
- Actually, even simpler: we don't need to yield the tool result as a text delta at all. The client's `onComplete(result)` callback receives the accumulated text. If we yield just the clean tool result line at the end, `result` will contain only that clean line.

**Change 2: Detect misunderstood via function_call content type instead of regex on text.**

The root cause from UAT Test 3: `_MISUNDERSTOOD_RE` regex detection on `update.text` never matches because when the Classifier calls `request_misunderstood`, the tool's return value ("Misunderstood -> uuid | question") is consumed internally by the LLM -- it doesn't appear in `AgentResponseUpdate.text`. The LLM's text response is just the conversational question itself (no "Misunderstood -> uuid |" prefix).

Since `request_info` events fire when the non-autonomous Classifier calls `request_misunderstood` (because the Classifier is not in autonomous mode), we need to look at how the request_info data carries information about which tool was called.

However, the UAT diagnosis says: "Regex-based detection of request_misunderstood tool output in streamed text never matches because tool return values are consumed internally by the LLM -- they don't appear in AgentResponseUpdate.text."

But wait -- `request_misunderstood` is a tool that the Classifier calls. When a non-autonomous agent calls a tool, the framework:
1. Executes the tool (which creates the inbox doc and returns "Misunderstood -> uuid | question")
2. The tool result goes back to the LLM
3. The LLM generates a text response (the conversational question)
4. The framework emits the LLM's text as output events
5. Then the framework emits a request_info event (because the agent is non-autonomous and needs user response)

So the tool result text ("Misunderstood -> uuid | question") MAY appear in the output events if the LLM echoes it, but it often doesn't -- the LLM just generates the conversational question.

The fix: Instead of relying on regex matching on the streamed text, detect misunderstood by examining the function_call/tool_call content in AgentResponseUpdate. Check if any update from the Classifier contains a function_call content item where the function name is "request_misunderstood". AgentResponseUpdate has a `contents` list -- check if any content item has `type == "function_call"` or similar.

Actually, looking at the Agent Framework more carefully: the tool execution happens inside the workflow. The tool result might be in the "data" WorkflowEvent. Let me think about what the actual events look like...

The Classifier calls `request_misunderstood`. The tool runs and returns "Misunderstood -> {uuid} | {question}". This return value goes back to the Classifier LLM as a tool result. The LLM then generates its response text (the conversational question). The framework emits the response as an output event. Then since Classifier is non-autonomous, it emits request_info.

So the tool result string "Misunderstood -> uuid | question" might be in:
- A `data` WorkflowEvent containing the tool result
- The `request_info` event data (which wraps the agent's response)

Currently the code already tries to extract from request_info data (lines 271-287). But it only checks for `_CLARIFICATION_RE`, not `_MISUNDERSTOOD_RE`.

**The fix for misunderstood detection** is to ALSO check for `_MISUNDERSTOOD_RE` in the request_info event data, just like it already checks for `_CLARIFICATION_RE`. Add a parallel check in the `request_info` handler block (around line 266-287):

After the existing clarification extraction attempt in the `request_info` handler, add:
```python
if detected_misunderstood is None:
    mis = self._extract_misunderstood(request_text)
    if mis is not None:
        detected_misunderstood = mis
        logger.info("Extracted misunderstood from request_info data")
```

Also, check the `data` WorkflowEvents for misunderstood patterns. When `event.type == "data"`, the event.data might contain tool results. Add extraction there too.

But most importantly: also try to extract misunderstood from the `classifier_buffer` at the end. If the LLM DID echo the tool result pattern, the buffer will have it.

And if NONE of those work (the text detection fails), fall back to: if `saw_request_info` is True and `detected_clarification` is None and `detected_confidence` is None, then check if the Classifier had `request_misunderstood` in its tool list. But we can't easily check that.

**Simplest reliable fix**: The request_info event data contains the full agent response including tool results. Extract misunderstood from there (parallel to the existing clarification extraction). This is the most reliable path because request_info is always emitted when the non-autonomous Classifier pauses.

Here's the specific code change in the `request_info` handler (around line 266):

Current code checks for clarification. Add misunderstood check BEFORE clarification check (since misunderstood should take priority per phase 04.3 design):

```python
if event.type == "request_info":
    logger.info("request_info received -- workflow paused for HITL")
    saw_request_info = True
    request_data = event.data
    request_text = ""
    if hasattr(request_data, "response"):
        resp = request_data.response
        if hasattr(resp, "text"):
            request_text = resp.text
    elif hasattr(request_data, "text"):
        request_text = request_data.text

    # Check misunderstood FIRST (higher priority)
    if request_text and detected_misunderstood is None:
        mis = self._extract_misunderstood(request_text)
        if mis is not None:
            detected_misunderstood = mis
            logger.info("Extracted misunderstood from request_info data")

    # Then check clarification
    if request_text and detected_clarification is None and detected_misunderstood is None:
        clar = self._extract_clarification(request_text)
        if clar is not None:
            detected_clarification = clar
            logger.info("Extracted clarification from request_info data")
    continue
```

Also, the request_info handler only extracts text from `request_data.response.text` or `request_data.text`. But the tool result might be in a different field. Check if HandoffAgentUserRequest has the tool call results in another attribute. Add logging to inspect the request_data structure:
```python
logger.info("request_info data type=%s, attrs=%s", type(request_data).__name__, dir(request_data))
```

If the tool result is not in .response.text or .text, try iterating over the response contents:
```python
if hasattr(request_data, "response") and hasattr(request_data.response, "content"):
    for content in (request_data.response.content or []):
        if hasattr(content, "text"):
            request_text += content.text + "\n"
        elif hasattr(content, "result"):
            request_text += str(content.result) + "\n"
```

This broader extraction should capture tool results that appear as content items.

**Summary of changes to workflow.py:**

1. Add `_TOOL_RESULT_RE` regex combining all tool result patterns
2. Add `_is_classifier_text` method
3. In `_stream_updates`: add `classifier_buffer = ""`
4. Buffer Classifier text updates instead of yielding them
5. Run misunderstood/clarification/confidence detection on the buffer after each append
6. After stream loop: extract clean tool result from buffer, yield single update if found
7. In `request_info` handler: add misunderstood extraction (parallel to existing clarification extraction)
8. In `request_info` handler: broaden text extraction to include response content items
  </action>
  <verify>
Run `cd /Users/willmacdonald/Documents/Code/claude/second-brain/backend && python -m pytest tests/ -v` -- all existing tests must pass (43 tests). Then verify the regex patterns by running a quick Python snippet:

```python
import re
_TOOL_RESULT_RE = re.compile(r"(Filed\s*(?:\(needs review\)\s*)?→\s*\w+\s*\(\d+\.\d+\)|Misunderstood\s*→\s*[a-f0-9\-]+\s*\|.+|Clarification\s*→\s*[a-f0-9\-]+\s*\|.+)")
assert _TOOL_RESULT_RE.search("Filed → Admin (0.90)")
assert _TOOL_RESULT_RE.search("Filed (needs review) → People (0.55)")
assert _TOOL_RESULT_RE.search("Misunderstood → abc-123 | What did you mean?")
```
  </verify>
  <done>
(1) Classifier chain-of-thought reasoning text is buffered and suppressed; only the clean tool result line (e.g., "Filed -> Admin (0.90)") is yielded to the SSE stream.
(2) Misunderstood detection works reliably via request_info data extraction (not just regex on streamed text).
(3) All 43 existing backend tests still pass.
  </done>
</task>

</tasks>

<verification>
- `python -m pytest tests/ -v` in backend directory: all tests pass
- Regex patterns correctly match all three tool result formats
- No Classifier reasoning text reaches the client (only tool result lines)
- MISUNDERSTOOD event emitted when request_misunderstood tool is called
</verification>

<success_criteria>
- Classifier chain-of-thought text is filtered from the SSE stream
- Only clean tool result text ("Filed -> X (0.XX)" or "Filed (needs review) -> X (0.XX)") reaches the client
- MISUNDERSTOOD custom event is reliably emitted when the Classifier calls request_misunderstood
- All 43 existing backend tests pass with no regressions
</success_criteria>

<output>
After completion, create `.planning/phases/04.3-agent-user-ux-with-unclear-item/04.3-05-SUMMARY.md`
</output>
