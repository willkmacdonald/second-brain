# Phase 04.3: Agent-User UX with Unclear Item - Research

**Researched:** 2026-02-23
**Domain:** Classification UX flows (misunderstood, low-confidence, mis-categorized), LLM confidence heuristics, Cosmos DB cross-container moves
**Confidence:** HIGH

## Summary

This phase extends the existing capture-classify-HITL pipeline (built in Phase 4) with three distinct classification failure flows. The codebase already handles one scenario (low-confidence -> HITL bucket buttons), but needs to distinguish between truly misunderstood input (requiring conversational follow-up on the capture screen) and merely low-confidence classification (silent pending filing). It also needs a new recategorize flow for items the classifier was confidently wrong about.

The existing architecture is well-suited for extension. The backend already has the `AGUIWorkflowAdapter` with HITL detection, `ClassificationTools` with `request_clarification` and `mark_as_junk`, and an `InboxDocument` model with `status` and `clarificationText` fields. The mobile app has a capture screen with inline HITL UI, an inbox with detail modals, and a conversation screen. The primary engineering challenge is (1) adding a "misunderstood" detection heuristic that triggers a conversational follow-up loop on the capture screen, (2) changing the current HITL interruption for low-confidence items to a silent pending flow, and (3) building the recategorize endpoint and inbox detail card UI with bucket buttons.

**Primary recommendation:** Implement a two-threshold classification system where a second lower threshold (or score distribution entropy check) distinguishes "misunderstood" from "low-confidence", add a multi-turn follow-up exchange on the capture screen for misunderstood items, convert low-confidence items to silent pending filing, and add a recategorize endpoint with inbox detail card bucket buttons.

<user_constraints>
## User Constraints (from CONTEXT.md)

### Locked Decisions

**Three distinct classification outcome flows:**

**Flow 1: Misunderstood (agent can't make sense of input)**
- Hybrid approach: agent guesses if it has any reasonable interpretation, asks open-ended "What did you mean?" if truly no idea
- Conversational, friendly tone -- "I'm not quite sure what you meant by..."
- Happens immediately on capture screen -- agent sends open-ended question, user responds via text
- Agent's question text remains visible above the text input so user knows they're replying to a follow-up (not starting a new capture)
- Same text input reused for the response (clears for reply)
- Agent re-runs classification on original text + user's clarification
- Maximum 2 follow-up exchanges; if still unresolved after 2 rounds, item goes to "unresolved" status in inbox
- Unresolved items stay in inbox with distinct status; user can open later to manually categorize or retry

**Flow 2: Low confidence (score under threshold but not misunderstood)**
- Item auto-filed as "pending" status -- NO immediate user interaction required
- User discovers it later in inbox at their leisure
- Tapping a pending item in inbox opens detail card with: original user text + 4 bucket buttons for manual resolution
- This is the existing flow refined -- pending items don't block the user

**Flow 3: Mis-categorized (high confidence, wrong bucket)**
- Item was auto-filed to wrong bucket
- User discovers it in inbox, taps to open detail card
- Detail card has 4 bucket buttons at the bottom
- Current bucket is visually highlighted so user knows where it's filed
- Tapping a different bucket recategorizes instantly -- no confirmation dialog
- Toast confirms: "Moved to [Bucket]"
- Backend moves the record: deletes from wrong bucket container, creates in correct one
- Only available for classified items (not pending/unresolved)
- Bucket change only -- no text editing in this flow

**Misunderstood vs low-confidence distinction:**
- Claude's discretion on the heuristic for distinguishing "misunderstood" from "low confidence"
- Could be a second lower threshold, score distribution analysis, or other approach
- Key behavior: misunderstood triggers immediate conversation; low confidence triggers silent pending status

**Inbox visual indicators:**
- Color-coded status dots in inbox list:
  - Orange dot: pending / low-confidence (needs user bucket selection)
  - Red dot: unresolved (agent couldn't classify after 2 follow-ups)
  - Green dot (or no dot): classified and filed successfully
- These replace or extend the existing orange dot for pending items

**Recategorize API design:**
- Claude's discretion on whether to create a new endpoint (e.g., PATCH /api/inbox/{id}/recategorize) or extend existing respond endpoint

### Claude's Discretion

- Heuristic for distinguishing misunderstood vs low-confidence (threshold, score distribution, etc.)
- API endpoint design for recategorize
- Exact animation/transition when recategorizing
- Loading states during re-classification in misunderstood flow

### Deferred Ideas (OUT OF SCOPE)

- Voice as default response method for misunderstood follow-ups (after Phase 5 -- Voice Capture)
- Text editing of raw capture text from inbox (not in scope for recategorize)
- Logging correction history for classifier improvement (keeping trace of original vs corrected bucket)
</user_constraints>

## Standard Stack

### Core (already in project)

| Library | Version | Purpose | Why Standard |
|---------|---------|---------|--------------|
| FastAPI | current | Backend API | Already in project; async endpoints |
| Pydantic | current | Data models | Already used for InboxDocument, ClassificationMeta |
| Azure Cosmos DB SDK | current | Data layer | Already used via CosmosManager |
| React Native | current | Mobile app | Already used |
| Expo Router | current | Navigation | Already used for tab/stack navigation |
| react-native-sse | current | SSE streaming | Already used in ag-ui-client.ts |

### Supporting (no new libraries needed)

This phase requires NO new libraries. All three flows are achievable with the existing stack by extending current patterns:

- Backend: New/modified tools in `ClassificationTools`, modified `AGUIWorkflowAdapter`, new/extended API endpoints in `inbox.py`
- Mobile: Extended capture screen state machine, modified inbox detail modal, new visual indicators in `InboxItem`

### Alternatives Considered

| Instead of | Could Use | Tradeoff |
|------------|-----------|----------|
| Custom multi-turn on capture screen | Full chat SDK (Stream, etc.) | Massive overkill for 2-exchange follow-up; custom is simpler |
| Entropy-based misunderstood detection | Separate "clarity" LLM call | Extra LLM round-trip adds latency; score analysis is free |
| New recategorize endpoint | Extend existing respond endpoint | New endpoint is cleaner separation of concerns |

## Architecture Patterns

### Current Project Structure (relevant files)

```
backend/src/second_brain/
├── agents/
│   ├── classifier.py          # Classifier agent with instructions
│   ├── orchestrator.py        # Routes to Classifier
│   └── workflow.py            # AGUIWorkflowAdapter with HITL detection
├── api/
│   └── inbox.py               # GET/DELETE inbox endpoints
├── models/
│   └── documents.py           # InboxDocument, ClassificationMeta, bucket docs
├── tools/
│   └── classification.py      # classify_and_file, request_clarification, mark_as_junk
├── config.py                  # Settings with classification_threshold
└── main.py                    # FastAPI app, AG-UI endpoint, respond endpoint

mobile/
├── app/
│   ├── capture/text.tsx        # Text capture screen with inline HITL
│   ├── (tabs)/inbox.tsx        # Inbox list with detail modal
│   └── conversation/[threadId].tsx  # Conversation screen for pending items
├── components/
│   └── InboxItem.tsx           # Inbox list row with status dot
├── lib/
│   ├── ag-ui-client.ts         # sendCapture, sendClarification SSE clients
│   └── types.ts                # StreamingCallbacks, AGUIEventType
└── constants/
    └── config.ts               # API_BASE_URL, API_KEY
```

### Pattern 1: Misunderstood Detection Heuristic (Claude's Discretion)

**What:** A heuristic in the Classifier agent instructions and/or `ClassificationTools` that distinguishes "misunderstood" (agent truly cannot interpret the input) from "low confidence" (agent can classify but is uncertain between buckets).

**Recommendation: Dual-threshold + score distribution entropy approach.**

Current system: single threshold at 0.6. Below 0.6 = low confidence, calls `request_clarification`.

Proposed system with two thresholds and an entropy check:

1. **Confidence >= 0.6**: High confidence -> auto-file (unchanged)
2. **Confidence 0.3-0.59**: Low confidence -> silent pending filing (Flow 2)
3. **Confidence < 0.3 OR high entropy (all scores within ~0.05 of each other)**: Misunderstood -> immediate conversation (Flow 1)

**Why this approach:**
- Research on LLM self-assessed confidence (Nyckel blog, ACL 2025) shows that raw LLM confidence scores are poorly calibrated and often overconfident. A single threshold does not capture the qualitative difference between "uncertain between two plausible buckets" and "this input makes no sense."
- Score distribution provides a secondary signal: if all 4 bucket scores are roughly equal (~0.25 each), the classifier has no meaningful signal -- the input is likely gibberish or so ambiguous it needs clarification. If one score is notably higher than the rest (even at 0.45), the classifier has a reasonable guess.
- The existing `mark_as_junk` tool already handles pure gibberish. Misunderstood is for real text that the agent cannot meaningfully categorize.

**Implementation in classifier instructions:**

```
## Misunderstood vs Low-Confidence

When confidence is below 0.6, evaluate whether you UNDERSTAND the input:

- If you can determine the user's likely intent but are torn between 2 buckets:
  Call request_clarification (low confidence -- pending filing)

- If you genuinely cannot determine what the user meant, or the text is
  too fragmentary/ambiguous to assign ANY bucket meaningfully:
  Call request_misunderstood (misunderstood -- conversational follow-up)

Signals of "misunderstood":
- All 4 bucket scores within 0.10 of each other (no clear winner)
- Text is a single ambiguous word or very short fragment
- Text could mean completely different things in different contexts
- Confidence below 0.30 for the top bucket
```

**Confidence:** HIGH -- This approach uses existing score data (no new LLM calls), aligns with research on confidence calibration, and keeps the distinction in the Classifier's instructions where it belongs.

### Pattern 2: Multi-Turn Conversation on Capture Screen

**What:** When the classifier triggers "misunderstood", the capture screen enters a conversation mode where the agent's question appears above the text input, the user types a response, and the system re-classifies with the combined context.

**How it maps to the existing architecture:**

1. Backend: New tool `request_misunderstood` in `ClassificationTools` -- similar to `request_clarification` but creates an InboxDocument with status `"misunderstood"` and stores the agent's open-ended question.
2. Adapter: New custom event `MISUNDERSTOOD` (distinct from `HITL_REQUIRED`) emitted by `AGUIWorkflowAdapter` when it detects the misunderstood pattern in tool output.
3. Mobile: Capture screen handles `MISUNDERSTOOD` event by entering conversation mode -- shows agent question, clears text input for user reply, tracks follow-up count (max 2).
4. New backend endpoint: `POST /api/ag-ui/follow-up` that accepts `{ inbox_item_id, original_text, follow_up_text, follow_up_round }` -- re-runs classification with combined context `"{original_text}\n\nUser clarification: {follow_up_text}"`.
5. After 2 failed rounds: status set to `"unresolved"` and item stays in inbox.

**State machine for capture screen:**

```
IDLE -> [user submits] -> CLASSIFYING
CLASSIFYING -> [high confidence] -> FILED -> [auto-reset] -> IDLE
CLASSIFYING -> [low confidence] -> FILED_PENDING -> [auto-reset] -> IDLE
CLASSIFYING -> [misunderstood] -> FOLLOW_UP_1
FOLLOW_UP_1 -> [user replies] -> RE_CLASSIFYING_1
RE_CLASSIFYING_1 -> [classified] -> FILED -> IDLE
RE_CLASSIFYING_1 -> [still misunderstood] -> FOLLOW_UP_2
FOLLOW_UP_2 -> [user replies] -> RE_CLASSIFYING_2
RE_CLASSIFYING_2 -> [classified] -> FILED -> IDLE
RE_CLASSIFYING_2 -> [still unclear] -> UNRESOLVED -> [auto-reset] -> IDLE
```

**Confidence:** HIGH -- This follows the existing pattern (capture screen already handles HITL with state variables) and just extends it with follow-up rounds.

### Pattern 3: Silent Pending Filing for Low-Confidence Items

**What:** Low-confidence items (0.3-0.59) are auto-filed with `status: "pending"` and the user is NOT interrupted. They appear in inbox with an orange dot for later resolution.

**How this changes the current flow:**

Currently: Low confidence -> `request_clarification` tool -> workflow pauses -> HITL_REQUIRED event -> bucket buttons on capture screen -> user must respond immediately.

New flow: Low confidence -> `classify_and_file` tool with `status: "pending"` -> workflow completes normally -> capture screen shows toast "Captured (needs review)" -> item appears in inbox with orange dot -> user resolves at leisure via inbox detail card.

**Key change:** The Classifier agent instructions must be updated so that for confidence 0.3-0.59, it calls `classify_and_file` with its best guess (not `request_clarification`). The `classify_and_file` tool already sets `status = "low_confidence"` for below-threshold scores.

**Impact on existing `request_clarification` tool:** It would only be called for the misunderstood flow (renamed/repurposed), or could be replaced entirely by a new `request_misunderstood` tool. The current `request_clarification` creates a pending inbox doc -- this behavior shifts to `classify_and_file` for low-confidence cases.

**Confidence:** HIGH -- Simplifies the flow by removing the HITL interruption for low-confidence cases, which is the desired UX.

### Pattern 4: Recategorize Flow (Inbox Detail Card -> Move Bucket)

**What:** User opens a classified item's detail card in inbox, sees 4 bucket buttons with current bucket highlighted, taps a different bucket to instantly recategorize.

**Backend:**

Option A: New `PATCH /api/inbox/{id}/recategorize` endpoint (RECOMMENDED)
- Request body: `{ "new_bucket": "Projects" }`
- Logic: Read inbox item -> delete old bucket doc -> create new bucket doc -> update inbox doc (bucket, filedRecordId, agentChain += "User", classifiedBy = "User")
- Returns: Updated inbox item
- No SSE needed -- synchronous REST call

Option B: Extend existing `/api/ag-ui/respond` endpoint
- Already handles bucket selection for pending items
- Would need to also handle classified items (different logic: move vs first-time file)
- Mixes concerns: SSE streaming response for a synchronous operation

**Recommendation: Option A (new endpoint)** because:
1. Recategorize is a synchronous operation (delete old + create new) -- no need for SSE streaming
2. Clean separation: `respond` handles first-time filing of pending items, `recategorize` handles moving already-filed items
3. Simpler client code: `fetch()` with `await` instead of SSE EventSource

**Cosmos DB cross-container "move":** There is no atomic cross-container transaction in Cosmos DB (transactions are limited to single partition key within a single container). The move must be: (1) create new bucket document, (2) update inbox document, (3) delete old bucket document. If step 3 fails, the old doc is orphaned but the inbox doc has correct metadata. This is acceptable for a personal app.

**Order of operations matters:**
1. Create new bucket doc FIRST (if this fails, nothing has changed)
2. Update inbox doc (point to new bucket doc)
3. Delete old bucket doc LAST (if this fails, orphaned doc is harmless)

**Confidence:** HIGH -- The delete-then-create pattern is already used in the `respond_to_hitl` endpoint (minus the delete). Cosmos DB limitations are well understood.

### Pattern 5: Inbox Visual Indicators (Status Dots)

**What:** Color-coded dots in the inbox list based on item status.

**Implementation in `InboxItem.tsx`:**

```typescript
// Status dot color mapping
const STATUS_DOT_COLORS: Record<string, string> = {
  pending: "#f97316",      // Orange -- needs user bucket selection
  low_confidence: "#f97316", // Orange -- same as pending
  misunderstood: "#f97316",  // Orange -- in-progress on capture screen
  unresolved: "#ef4444",     // Red -- agent gave up after 2 rounds
  classified: "transparent", // No dot (or green)
};
```

The existing `InboxItem` component already has an orange dot for pending/low_confidence items. Extension to red dot for unresolved is trivial -- just add the new status check and color.

**For classified items in the detail card:** The current detail modal shows bucket and confidence. Adding 4 bucket buttons at the bottom with the current bucket highlighted is straightforward. The current bucket is already available from `classificationMeta.bucket`.

**Confidence:** HIGH -- Minimal UI change, extending existing pattern.

### Anti-Patterns to Avoid

- **Don't re-run the full Orchestrator -> Classifier workflow for follow-ups.** The follow-up endpoint should call the Classifier directly with combined context, not re-enter the workflow. The Orchestrator just routes to Classifier anyway.
- **Don't use SSE for the recategorize endpoint.** It's a synchronous operation -- use a standard REST response.
- **Don't block the user for low-confidence items.** The whole point of Flow 2 is that low-confidence items are silently filed and resolved later.
- **Don't share the "misunderstood" state between capture screen sessions.** Each capture session is independent. If the user navigates away during a misunderstood follow-up, the item should go to inbox with its current status.
- **Don't add a confirmation dialog for recategorize.** The user explicitly tapped a different bucket -- instant move with toast undo is the UX pattern (though undo is not in scope; toast confirmation is sufficient).

## Don't Hand-Roll

| Problem | Don't Build | Use Instead | Why |
|---------|-------------|-------------|-----|
| Confidence calibration | Post-hoc calibration pipeline | LLM instruction tuning + dual threshold | No labeled calibration dataset exists; instruction-based threshold is practical |
| Cross-container transaction | Custom distributed transaction | Sequential create-update-delete | Cosmos DB doesn't support cross-container ACID; sequential ops are sufficient for single-user app |
| Chat UI for follow-ups | Full chat component library | Extend existing capture screen state | Only 2 follow-up exchanges; full chat is overkill |
| Status dot system | Custom badge/indicator library | Inline View with backgroundColor | 3 colors, 1 dot -- no library needed |

**Key insight:** This phase extends existing patterns rather than introducing new ones. The capture screen already handles HITL; the inbox already has detail modals; the backend already has classification tools. Every new flow maps cleanly to existing architecture.

## Common Pitfalls

### Pitfall 1: LLM Overconfidence on Ambiguous Input

**What goes wrong:** The Classifier assigns high confidence (0.75+) to genuinely ambiguous inputs, causing them to auto-file to the wrong bucket. User noted this already happens with some intentionally ambiguous test inputs.

**Why it happens:** LLM self-assessed confidence is poorly calibrated (Nyckel research shows inverse correlation between stated confidence and accuracy in some datasets). GPT models tend toward overconfidence.

**How to avoid:** Add calibration examples to Classifier instructions showing cases where the model should be LESS confident. Include the user's observed cases (ambiguous inputs rated high) as negative examples in the prompt. Consider adding a "confidence sanity check" instruction: "If the text mentions elements from 2+ buckets equally, your confidence MUST be below 0.65 regardless of how clear each individual element is."

**Warning signs:** Items appearing in wrong buckets during testing. All test inputs getting confidence > 0.75.

### Pitfall 2: Follow-Up Context Getting Lost

**What goes wrong:** When the user responds to a misunderstood follow-up, the re-classification doesn't have access to the original text, or the combined context is malformed.

**Why it happens:** The follow-up endpoint receives only the user's reply, not the original text. Or the original text + reply are concatenated without clear separation.

**How to avoid:** Store the original raw text in the inbox document (already done). The follow-up endpoint reads the inbox document to get the original text, then combines: `"{original_text}\n\n---\nUser clarification: {follow_up_text}"`. Pass this combined text to the Classifier.

**Warning signs:** Re-classification after follow-up produces worse results than the original classification.

### Pitfall 3: Stale Inbox State After Recategorize

**What goes wrong:** User recategorizes an item in the detail card, but the inbox list still shows the old bucket/status until manual refresh.

**Why it happens:** The inbox list is fetched once and not updated after the recategorize API call returns.

**How to avoid:** After a successful recategorize API call, update the local state optimistically (change the item's bucket in the items array) and close the detail modal. Show the toast "Moved to [Bucket]". Optionally re-fetch inbox in background to sync.

**Warning signs:** Bucket label in inbox list doesn't match what was just selected.

### Pitfall 4: Race Condition in Misunderstood Follow-Up

**What goes wrong:** User submits a follow-up while the previous re-classification is still in progress, causing duplicate submissions or state corruption.

**Why it happens:** The text input is available for typing while the classification is running.

**How to avoid:** Disable the Send button and text input while re-classification is in progress (same pattern as current `sending` state). Track `isReclassifying` state.

**Warning signs:** Multiple inbox documents created for the same capture.

### Pitfall 5: Cosmos DB Delete-Then-Create Partial Failure

**What goes wrong:** During recategorize, the new bucket doc is created but the old one isn't deleted (or vice versa).

**Why it happens:** Cosmos DB doesn't support cross-container transactions. Network errors can cause partial completion.

**How to avoid:** Order operations as create-new -> update-inbox -> delete-old. If the delete fails, the orphaned document is harmless (no UI references it; inbox points to the new doc). Log warnings for failed deletes so they can be cleaned up later.

**Warning signs:** Duplicate documents in bucket containers.

## Code Examples

### Example 1: New `request_misunderstood` Tool

```python
# Source: Extension of existing ClassificationTools pattern in
# backend/src/second_brain/tools/classification.py

@tool
async def request_misunderstood(
    self,
    raw_text: Annotated[str, "The original captured text"],
    question_text: Annotated[
        str,
        "A friendly, open-ended question asking the user what they meant. "
        "Example: \"I'm not quite sure what you meant by 'Aardvark'. "
        "Could you tell me more about what you were thinking?\""
    ],
    follow_up_round: Annotated[int, "Which follow-up round (1 or 2)"] = 1,
) -> str:
    """Request conversational follow-up when the input is truly misunderstood.

    Creates or updates an Inbox document with status 'misunderstood'.
    Unlike request_clarification (low confidence between known buckets),
    this is for inputs where the agent cannot determine ANY reasonable bucket.
    """
    inbox_doc_id = str(uuid4())

    inbox_doc = InboxDocument(
        id=inbox_doc_id,
        rawText=raw_text,
        source="text",
        title=None,  # Can't extract title from misunderstood text
        status="misunderstood",
        clarificationText=question_text,
        filedRecordId=None,
        classificationMeta=None,  # No meaningful scores
    )

    inbox_container = self._manager.get_container("Inbox")
    await inbox_container.create_item(body=inbox_doc.model_dump(mode="json"))

    logger.info("Misunderstood: '%s' (round %d)", raw_text[:80], follow_up_round)
    return f"Misunderstood -> {inbox_doc_id} | {question_text}"
```

### Example 2: Follow-Up Endpoint

```python
# Source: New endpoint in backend/src/second_brain/main.py

class FollowUpRequest(BaseModel):
    """Request body for the misunderstood follow-up endpoint."""
    inbox_item_id: str
    follow_up_text: str
    follow_up_round: int = 1  # 1 or 2

@app.post("/api/ag-ui/follow-up", tags=["AG-UI"])
async def follow_up_misunderstood(
    request: Request, body: FollowUpRequest
) -> StreamingResponse:
    """Re-classify a misunderstood capture with additional user context.

    Reads the original text from the inbox document, combines it with the
    user's follow-up, and re-runs classification. If still unresolved after
    round 2, marks as 'unresolved'.
    """
    # Read original inbox item
    # Combine: original_text + user follow-up
    # Re-run classifier on combined text
    # If classified: update inbox doc, create bucket doc, stream result
    # If still misunderstood and round < 2: emit MISUNDERSTOOD event again
    # If still misunderstood and round >= 2: set status='unresolved', stream result
    ...
```

### Example 3: Recategorize Endpoint

```python
# Source: New endpoint in backend/src/second_brain/api/inbox.py

class RecategorizeRequest(BaseModel):
    """Request body for recategorizing an inbox item."""
    new_bucket: str  # "People", "Projects", "Ideas", or "Admin"

@router.patch("/api/inbox/{item_id}/recategorize")
async def recategorize_inbox_item(
    request: Request, item_id: str, body: RecategorizeRequest
) -> dict:
    """Move an already-classified inbox item to a different bucket.

    Operations (non-atomic, ordered for safety):
    1. Create new bucket document
    2. Update inbox document (new bucket, new filedRecordId)
    3. Delete old bucket document
    """
    cosmos_manager = getattr(request.app.state, "cosmos_manager", None)
    if cosmos_manager is None:
        raise HTTPException(status_code=503, detail="Cosmos DB not configured")

    # Validate new_bucket
    if body.new_bucket not in VALID_BUCKETS:
        raise HTTPException(status_code=400, detail=f"Invalid bucket: {body.new_bucket}")

    inbox_container = cosmos_manager.get_container("Inbox")
    item = await inbox_container.read_item(item=item_id, partition_key="will")

    old_bucket = (item.get("classificationMeta") or {}).get("bucket")
    old_filed_id = item.get("filedRecordId")

    if old_bucket == body.new_bucket:
        return dict(item)  # No-op

    # 1. Create new bucket document
    new_bucket_doc_id = str(uuid4())
    # ... build and create new bucket doc ...

    # 2. Update inbox document
    item["classificationMeta"]["bucket"] = body.new_bucket
    item["filedRecordId"] = new_bucket_doc_id
    item["classificationMeta"]["classifiedBy"] = "User"
    item["classificationMeta"]["agentChain"].append("User")
    item["updatedAt"] = datetime.now(UTC).isoformat()
    await inbox_container.upsert_item(body=item)

    # 3. Delete old bucket document (non-fatal)
    if old_filed_id and old_bucket:
        try:
            old_container = cosmos_manager.get_container(old_bucket)
            await old_container.delete_item(item=old_filed_id, partition_key="will")
        except Exception:
            logger.warning("Could not delete old bucket doc %s/%s", old_bucket, old_filed_id)

    return dict(item)
```

### Example 4: Capture Screen State Machine Extension

```typescript
// Source: Extension of mobile/app/capture/text.tsx

// New state for misunderstood flow
const [followUpRound, setFollowUpRound] = useState(0);
const [agentQuestion, setAgentQuestion] = useState<string | null>(null);
const [originalInboxItemId, setOriginalInboxItemId] = useState<string | null>(null);

// In the MISUNDERSTOOD event handler:
// callbacks.onMisunderstood = (inboxItemId, questionText) => {
//   setAgentQuestion(questionText);
//   setOriginalInboxItemId(inboxItemId);
//   setFollowUpRound(1);
//   setThought("");  // Clear input for user's reply
//   setSending(false);
// };

// Agent question visible above text input:
// {agentQuestion && (
//   <View style={styles.agentQuestionBubble}>
//     <Text style={styles.agentQuestionText}>{agentQuestion}</Text>
//   </View>
// )}
```

### Example 5: Inbox Detail Card with Bucket Buttons

```typescript
// Source: Extension of mobile/app/(tabs)/inbox.tsx detail modal

// Inside the detail card modal, after existing fields:
{selectedItem?.status === "classified" && (
  <View style={styles.recategorizeSection}>
    <Text style={styles.detailLabel}>Move to bucket</Text>
    <View style={styles.bucketRow}>
      {BUCKETS.map((bucket) => {
        const isCurrent = selectedItem?.classificationMeta?.bucket === bucket;
        return (
          <Pressable
            key={bucket}
            onPress={() => handleRecategorize(selectedItem.id, bucket)}
            disabled={isCurrent || isRecategorizing}
            style={[
              styles.bucketButton,
              isCurrent && styles.bucketButtonCurrent,
            ]}
          >
            <Text style={[
              styles.bucketButtonText,
              isCurrent && styles.bucketButtonTextCurrent,
            ]}>
              {bucket}
            </Text>
          </Pressable>
        );
      })}
    </View>
  </View>
)}
```

## State of the Art

| Old Approach (Phase 4) | New Approach (Phase 04.3) | Impact |
|-------------------------|---------------------------|--------|
| Single threshold (0.6) for all uncertain items | Dual threshold (0.3/0.6) + entropy check | Distinguishes "can't understand" from "uncertain between buckets" |
| Low confidence interrupts user on capture screen | Low confidence silently files as pending | User not blocked; resolves at leisure in inbox |
| No misunderstood flow | Conversational follow-up (max 2 rounds) | Agent can ask open-ended questions for truly unclear input |
| No recategorize | Tap-to-move in inbox detail card | User can fix wrong classifications instantly |
| Single orange dot for pending | Orange (pending), Red (unresolved), Green/none (classified) | Clear visual status at a glance |

**Deprecated/outdated:**
- Phase 4's `request_clarification` flow on the capture screen (bucket buttons interrupting capture) is being replaced by silent pending filing + inbox resolution
- The conversation screen (`/conversation/[threadId].tsx`) may become unnecessary if pending items resolve via the inbox detail card directly

## Open Questions

1. **Should `request_clarification` be removed or repurposed?**
   - What we know: It currently creates a pending inbox doc and triggers HITL bucket buttons on the capture screen. With the new flow, low-confidence items auto-file silently.
   - What's unclear: Whether to keep it for backward compatibility or replace it entirely with `request_misunderstood` (for misunderstood flow) and modified `classify_and_file` (for low-confidence flow).
   - Recommendation: Remove `request_clarification` and replace with `request_misunderstood`. Modify `classify_and_file` to handle low-confidence filing (it already does via status field). This is cleaner than maintaining three similar tools.

2. **Follow-up endpoint: SSE streaming or synchronous?**
   - What we know: The follow-up re-runs classification, which takes 2-5 seconds. User needs visual feedback.
   - What's unclear: Whether to use SSE (like current AG-UI endpoint) or a synchronous endpoint with a loading spinner.
   - Recommendation: Use SSE streaming for follow-up (reuse existing `_stream_sse` helper), because the re-classification produces step events (Orchestrator -> Classifier) that provide meaningful progress feedback. The capture screen already handles SSE callbacks.

3. **What happens to existing pending/low_confidence items in production?**
   - What we know: There may be existing items with status "pending" or "low_confidence" in Cosmos DB from Phase 4 testing.
   - What's unclear: Whether these need migration or can be handled as-is.
   - Recommendation: No migration needed. The inbox already handles both statuses. The new detail card with bucket buttons will work for both existing and new pending items.

4. **Should the conversation screen be deprecated?**
   - What we know: Currently, tapping a pending item in inbox navigates to `/conversation/[threadId].tsx`. With the new flow, pending items would open a detail card with bucket buttons instead.
   - What's unclear: Whether to keep the conversation screen for any purpose.
   - Recommendation: Replace the conversation screen navigation with the detail card + bucket buttons approach (same as classified items, but without the "current bucket highlighted" since there's no definitive bucket yet). This is simpler and consistent.

## Sources

### Primary (HIGH confidence)

- Codebase analysis: `backend/src/second_brain/tools/classification.py` -- existing classify_and_file, request_clarification, mark_as_junk tools
- Codebase analysis: `backend/src/second_brain/agents/workflow.py` -- AGUIWorkflowAdapter with HITL detection patterns
- Codebase analysis: `backend/src/second_brain/agents/classifier.py` -- Classifier instructions with confidence thresholds
- Codebase analysis: `backend/src/second_brain/api/inbox.py` -- Inbox API endpoints (GET, DELETE with cascade)
- Codebase analysis: `backend/src/second_brain/main.py` -- AG-UI endpoint, respond endpoint, SSE helpers
- Codebase analysis: `mobile/app/capture/text.tsx` -- Capture screen state machine with HITL handling
- Codebase analysis: `mobile/app/(tabs)/inbox.tsx` -- Inbox list with detail modal
- Codebase analysis: `mobile/components/InboxItem.tsx` -- InboxItem with status dot
- Codebase analysis: `mobile/lib/ag-ui-client.ts` -- sendCapture and sendClarification SSE clients
- Codebase analysis: `backend/tests/test_classification.py` -- Test patterns for classification tools
- Codebase analysis: `backend/src/second_brain/models/documents.py` -- InboxDocument, ClassificationMeta models
- Azure Cosmos DB docs: Transactional batch limited to single partition key within single container (no cross-container ACID)

### Secondary (MEDIUM confidence)

- Nyckel blog (Aug 2024): "Calibrating LLM classification confidences" -- Shows GPT self-assessed confidence is poorly calibrated; inverse correlation between confidence and accuracy in some datasets; overconfidence is a known problem. Source: https://www.nyckel.com/blog/calibrating-gpt-classifications/
- ACL 2025 Findings: "Evaluating Large Language Models for Confidence-based Check Set Selection" -- LLMs struggle with uncertainty identification; individual confidence elicitation more reliable than batch. Source: https://aclanthology.org/2025.findings-acl.836.pdf
- NeurIPS 2025: ConfTuner paper -- LLMs generate incorrect answers with high confidence (overconfidence); calibration is an active research area. Source: https://openreview.net/forum?id=VZQ04Ojhu5

### Tertiary (LOW confidence)

- None -- all findings verified against codebase or published research.

## Metadata

**Confidence breakdown:**
- Standard stack: HIGH -- No new libraries; all extensions to existing patterns
- Architecture: HIGH -- Every pattern maps directly to existing codebase architecture
- Pitfalls: HIGH -- Based on direct codebase analysis + published LLM calibration research
- Heuristic for misunderstood detection: MEDIUM -- The dual-threshold approach is a reasonable starting point but may need tuning based on real-world usage. LLM calibration research confirms the overconfidence problem exists but doesn't prescribe exact thresholds for a 4-class system.

**Research date:** 2026-02-23
**Valid until:** 2026-03-23 (stable -- all technologies in use are established; LLM calibration research is ongoing but thresholds are tunable)
