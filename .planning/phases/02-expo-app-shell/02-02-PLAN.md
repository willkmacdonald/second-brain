---
phase: 02-expo-app-shell
plan: 02
type: execute
wave: 2
depends_on: [02-01]
files_modified:
  - mobile/lib/ag-ui-client.ts
  - mobile/lib/types.ts
  - mobile/constants/config.ts
  - mobile/app/capture/text.tsx
autonomous: true
requirements: [CAPT-01]

must_haves:
  truths:
    - "User can type a thought in the text capture screen"
    - "User can submit the thought with one tap of the Send button"
    - "Send button is disabled when the text field is empty"
    - "After successful send: brief 'Sent' toast appears, then auto-navigates back to main screen"
    - "On send error: error toast at the bottom, user stays on input screen with text preserved"
    - "Keyboard auto-opens when text capture screen appears"
    - "Thought is sent to the deployed Azure Container Apps backend via AG-UI endpoint"
  artifacts:
    - path: "mobile/app/capture/text.tsx"
      provides: "Full-screen text capture with TextInput, Send button, loading state, toast feedback"
      min_lines: 60
    - path: "mobile/lib/ag-ui-client.ts"
      provides: "SSE client using react-native-sse for AG-UI POST requests"
      min_lines: 40
    - path: "mobile/constants/config.ts"
      provides: "API_BASE_URL and USER_ID constants from EXPO_PUBLIC_ env vars"
      min_lines: 5
    - path: "mobile/lib/types.ts"
      provides: "Shared TypeScript types for AG-UI events and capture requests"
      min_lines: 10
  key_links:
    - from: "mobile/app/capture/text.tsx"
      to: "mobile/lib/ag-ui-client.ts"
      via: "import { sendCapture }"
      pattern: "import.*sendCapture.*from"
    - from: "mobile/lib/ag-ui-client.ts"
      to: "backend AG-UI endpoint"
      via: "POST to API_BASE_URL/api/ag-ui with Authorization: Bearer header"
      pattern: "Authorization.*Bearer"
    - from: "mobile/app/capture/text.tsx"
      to: "expo-router"
      via: "router.back() after successful send"
      pattern: "router\\.back"
---

<objective>
Build the text capture flow: typing a thought and sending it to the backend with one tap.

Purpose: Deliver the core capture interaction -- user types, taps Send, thought is POSTed to the AG-UI backend, user sees confirmation toast and returns to the main screen. This is fire-and-forget; the SSE response stream is consumed but not displayed (Phase 4 work).

Output: A working text capture screen connected to the deployed backend, completing the end-to-end capture loop.
</objective>

<execution_context>
@/Users/willmacdonald/.claude/get-shit-done/workflows/execute-plan.md
@/Users/willmacdonald/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-expo-app-shell/02-CONTEXT.md
@.planning/phases/02-expo-app-shell/02-RESEARCH.md
@.planning/phases/02-expo-app-shell/02-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create AG-UI SSE client, types, and config constants</name>
  <files>
    mobile/lib/ag-ui-client.ts
    mobile/lib/types.ts
    mobile/constants/config.ts
  </files>
  <action>
    **File 1: mobile/constants/config.ts**

    Export constants for backend connectivity:
    ```typescript
    export const API_BASE_URL = process.env.EXPO_PUBLIC_API_URL ?? "http://localhost:8003";
    export const API_KEY = process.env.EXPO_PUBLIC_API_KEY ?? "";
    export const USER_ID = "will"; // Single-user system per PROJECT.md
    ```

    Per locked decision: "Backend URL and API key stored in .env file using EXPO_PUBLIC_ prefix, baked in at build time."

    **File 2: mobile/lib/types.ts**

    Define TypeScript types for AG-UI event handling:
    ```typescript
    export type AGUIEventType =
      | "RUN_STARTED"
      | "TEXT_MESSAGE_START"
      | "TEXT_MESSAGE_CONTENT"
      | "TEXT_MESSAGE_END"
      | "RUN_FINISHED"
      | "RUN_ERROR";

    export interface SendCaptureOptions {
      message: string;
      apiKey: string;
      onComplete: () => void;
      onError: (error: string) => void;
    }
    ```

    Note: No `onDelta` callback -- per locked decision this is fire-and-forget. We don't display the SSE response (that's Phase 4). We only need onComplete and onError.

    **File 3: mobile/lib/ag-ui-client.ts**

    Build a thin SSE client using `react-native-sse` (NOT `@ag-ui/client` HttpAgent -- it uses browser ReadableStream which fails in React Native, per research anti-pattern).

    ```typescript
    import EventSource from "react-native-sse";
    import { API_BASE_URL } from "../constants/config";
    import type { SendCaptureOptions } from "./types";
    ```

    `sendCapture` function:
    - Creates an `EventSource` with:
      - URL: `${API_BASE_URL}/api/ag-ui`
      - method: `"POST"`
      - headers: `{ Authorization: "Bearer ${apiKey}", "Content-Type": "application/json" }`
      - body: JSON with `messages` array containing one user message (id: `msg-${Date.now()}`, role: "user", content: the message), `thread_id: "thread-${Date.now()}"`, `run_id: "run-${Date.now()}"`
      - `pollingInterval: 0` (CRITICAL: prevents auto-reconnection and duplicate captures, per research pitfall 3)

    - Event listeners:
      - `"RUN_FINISHED"`: call `onComplete()`, then `es.close()`
      - `"error"`: call `onError(event.message || "Connection error")`, then `es.close()`

    - Returns a cleanup function: `() => { es.removeAllEventListeners(); es.close(); }`

    Important: Do NOT listen for TEXT_MESSAGE_CONTENT or accumulate deltas. This is fire-and-forget per locked decision. We confirm send succeeded (RUN_FINISHED) or failed (error), nothing more.
  </action>
  <verify>
    - `ls mobile/lib/ag-ui-client.ts mobile/lib/types.ts mobile/constants/config.ts` -- all three files exist
    - `cd mobile && npx tsc --noEmit` -- TypeScript compiles cleanly
    - `grep "pollingInterval: 0" mobile/lib/ag-ui-client.ts` -- anti-reconnection safeguard present
    - `grep "Authorization" mobile/lib/ag-ui-client.ts` -- Bearer auth header present
  </verify>
  <done>
    AG-UI SSE client sends POST to the backend's /api/ag-ui endpoint with Bearer auth, handles RUN_FINISHED for success and error events for failure, and returns a cleanup function. Config constants read from EXPO_PUBLIC_ env vars. pollingInterval set to 0 to prevent duplicate captures.
  </done>
</task>

<task type="auto">
  <name>Task 2: Build text capture screen with submit, toast feedback, and auto-navigation</name>
  <files>
    mobile/app/capture/text.tsx
  </files>
  <action>
    Create the text capture screen at `mobile/app/capture/text.tsx`.

    **Layout (per locked decisions):**
    - Full-screen input view
    - Back button provided by the Stack header (configured in _layout.tsx from Plan 02-01)
    - Large text area filling most of the screen
    - Send button at the bottom
    - Dark background matching main screen (`#0f0f23`)

    **TextInput:**
    - `autoFocus={true}` (per locked decision: "Keyboard auto-opens on the text input screen")
    - `multiline={true}` -- large text area
    - `textAlignVertical="top"` -- text starts at top
    - `placeholder="What's on your mind?"` (Claude's discretion)
    - `placeholderTextColor="#666"`
    - Style: `flex: 1`, white text on dark background (`#1a1a2e`), rounded corners, padding
    - `value` and `onChangeText` bound to `thought` state

    **Send button:**
    - `Pressable` (not TouchableOpacity)
    - `disabled={!thought.trim() || sending}` (per locked decision: "Send button is disabled when the text field is empty")
    - Disabled style: `opacity: 0.4`
    - Pressed style: `opacity: 0.7`
    - Active style: blue/accent background (`#4a90d9`), white text
    - Label: "Send" when idle, "Sending..." when in progress (Claude's discretion: loading indicator)
    - Full width, large padding, rounded corners

    **Submit handler (handleSubmit):**
    1. Guard: if `!thought.trim() || sending` return early
    2. Set `sending = true`
    3. Trigger haptic: `Haptics.impactAsync(ImpactFeedbackStyle.Medium)`
    4. Get API key from config: `import { API_KEY } from "../../constants/config"`
    5. If no API key: show error toast and return
    6. Call `sendCapture({ message: thought.trim(), apiKey: API_KEY, onComplete, onError })`

    **onComplete callback (per locked decisions):**
    - Trigger success haptic: `Haptics.notificationAsync(NotificationFeedbackType.Success)`
    - Show "Sent" toast (brief -- use `Alert.alert("Sent")` or a simple custom toast; Claude's discretion on implementation)
    - After a short delay (~500ms), auto-navigate back: `router.back()`

    **onError callback (per locked decisions):**
    - Set `sending = false`
    - Show error toast at bottom: "Couldn't send — check connection" (exact text from locked decision)
    - User stays on input screen with text preserved (do NOT clear the thought state)

    **Toast implementation (Claude's discretion):**
    For simplicity, use a state-driven inline toast component at the bottom of the screen:
    ```typescript
    const [toast, setToast] = useState<{ message: string; type: "success" | "error" } | null>(null);
    ```
    Show a small colored bar at the bottom (green for success, red for error) that auto-dismisses after 2 seconds via `setTimeout`. This avoids adding a toast library dependency.

    **Keyboard handling:**
    Wrap in `KeyboardAvoidingView` with `behavior={Platform.OS === "ios" ? "padding" : "height"}` to keep Send button visible above keyboard.

    **Cleanup:**
    Use `useEffect` cleanup to call the cleanup function returned by `sendCapture` if the component unmounts while sending.
  </action>
  <verify>
    - `ls mobile/app/capture/text.tsx` -- file exists
    - `cd mobile && npx tsc --noEmit` -- TypeScript compiles cleanly
    - `grep "autoFocus" mobile/app/capture/text.tsx` -- auto-focus enabled
    - `grep "router.back" mobile/app/capture/text.tsx` -- auto-navigation back
    - `grep "Couldn't send" mobile/app/capture/text.tsx` -- error message matches locked decision
    - `grep "sendCapture" mobile/app/capture/text.tsx` -- connected to AG-UI client
    - `cd mobile && npx expo start` -- app launches, text capture screen accessible from main screen
  </verify>
  <done>
    Text capture screen has: auto-focused multiline TextInput, Send button disabled when empty, loading state while sending, "Sent" toast + auto-navigate back on success, "Couldn't send — check connection" error toast with text preserved on failure. Connected to AG-UI backend via sendCapture client. Keyboard stays visible without overlapping Send button.
  </done>
</task>

</tasks>

<verification>
1. Run `cd mobile && npx tsc --noEmit` -- no TypeScript errors across all files
2. Run `cd mobile && npx expo start` -- app starts without crashes
3. Open app: four buttons visible on main screen (from Plan 02-01)
4. Tap "Text" button: navigates to text capture screen
5. Verify keyboard auto-opens
6. Verify Send button is disabled when text area is empty
7. Type a thought, tap Send: "Sending..." state shown, then "Sent" toast, auto-navigates back
8. (With backend unreachable) Type a thought, tap Send: "Couldn't send — check connection" error toast, text preserved
9. Tap Back button: returns to main screen
</verification>

<success_criteria>
- Text capture screen loads with auto-focused keyboard
- Send button is disabled when text field is empty
- Typing text enables the Send button
- Sending a thought fires POST to AG-UI endpoint with Bearer auth
- Successful send shows "Sent" toast and auto-navigates to main screen
- Failed send shows error toast and preserves typed text
- Fire-and-forget: no SSE response content displayed
- pollingInterval: 0 prevents duplicate submissions
</success_criteria>

<output>
After completion, create `.planning/phases/02-expo-app-shell/02-02-SUMMARY.md`
</output>
