---
phase: 09.1-mobile-ux-review-and-refinements
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - mobile/app/(tabs)/index.tsx
autonomous: true
requirements:
  - UX-01
  - UX-02
  - UX-03
  - UX-04
  - UX-05

must_haves:
  truths:
    - "User sees two equal-size toggle buttons (Voice/Text) at top of capture screen, with voice pre-selected on startup"
    - "Tapping Text toggle shows text input with placeholder and embedded Send button -- no navigation to a different screen"
    - "Tapping Voice toggle shows the record button centered in the content area"
    - "Text capture sends via sendCapture and shows 'Classifying...' processing stage inline"
    - "Voice capture shows 'Uploading...' then 'Classifying...' processing stages inline"
    - "Follow-up mode switching uses the top Voice/Text toggles -- no 'Type instead'/'Record instead' links"
    - "Low-confidence bucket buttons appear on the unified screen"
    - "Photo and Video buttons are gone"
  artifacts:
    - path: "mobile/app/(tabs)/index.tsx"
      provides: "Unified capture screen with voice/text toggle, text capture, processing stages, HITL flows"
  key_links:
    - from: "mobile/app/(tabs)/index.tsx"
      to: "mobile/lib/ag-ui-client.ts"
      via: "import sendCapture, sendVoiceCapture, sendFollowUp, sendFollowUpVoice"
      pattern: "import.*sendCapture.*ag-ui-client"
---

<objective>
Refactor the main capture screen into a unified Voice/Text experience with inline text capture, granular processing feedback, and follow-up mode switching via top toggles.

Purpose: Eliminate the redundant text capture screen by merging all capture functionality into `(tabs)/index.tsx`. The user should never navigate away from the capture tab to file a thought.

Output: A single unified capture screen that handles voice recording, text input, processing feedback stages, HITL bucket selection, and misunderstood follow-up -- all controlled by Voice/Text toggle buttons at the top.
</objective>

<execution_context>
@/Users/willmacdonald/.claude/get-shit-done/workflows/execute-plan.md
@/Users/willmacdonald/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/STATE.md
@.planning/ROADMAP.md
@.planning/phases/09.1-mobile-ux-review-and-refinements/09.1-CONTEXT.md
@.planning/phases/09.1-mobile-ux-review-and-refinements/09.1-RESEARCH.md

@mobile/app/(tabs)/index.tsx
@mobile/app/capture/text.tsx
@mobile/lib/ag-ui-client.ts
@mobile/components/CaptureButton.tsx
@mobile/components/AgentSteps.tsx

<interfaces>
<!-- Key functions from ag-ui-client.ts that the unified screen must import -->

From mobile/lib/ag-ui-client.ts:
```typescript
export function sendCapture({
  message, apiKey, callbacks,
}: SendCaptureOptions): { cleanup: () => void; threadId: string };

export function sendVoiceCapture({
  audioUri, apiKey, callbacks,
}: SendVoiceCaptureOptions): () => void;

export function sendFollowUp({
  inboxItemId, followUpText, followUpRound, apiKey, callbacks,
}: SendFollowUpOptions): () => void;

export function sendFollowUpVoice({
  audioUri, inboxItemId, followUpRound, apiKey, callbacks,
}: SendFollowUpVoiceOptions): () => void;
```

StreamingCallbacks interface (same across all four functions):
```typescript
interface StreamingCallbacks {
  onStepStart?: (stepName: string) => void;
  onStepFinish?: (stepName: string) => void;
  onTextDelta?: (delta: string) => void;
  onLowConfidence?: (inboxItemId: string, bucket: string, confidence: number) => void;
  onMisunderstood?: (threadId: string, questionText: string, inboxItemId: string) => void;
  onUnresolved?: (inboxItemId: string) => void;
  onHITLRequired?: (threadId: string, questionText: string, inboxItemId?: string) => void;
  onComplete?: (result: string) => void;
  onError?: (error: string) => void;
}
```
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Replace button grid with Voice/Text toggle and add text capture mode</name>
  <files>mobile/app/(tabs)/index.tsx</files>
  <action>
Rewrite `(tabs)/index.tsx` to be the unified capture screen. This is a significant refactor of the existing file.

**Imports to add:**
- Add `sendCapture` to the import from `../../lib/ag-ui-client` (currently only imports `sendVoiceCapture`, `sendFollowUp`, `sendFollowUpVoice`)
- Add `ActivityIndicator` to the react-native import
- REMOVE `import { router } from "expo-router"` (no longer navigating to text screen)
- REMOVE `import { CaptureButton } from "../../components/CaptureButton"` (replaced by inline toggle buttons)
- REMOVE `import { AgentSteps } from "../../components/AgentSteps"` (replaced by processing stage text)

**State changes:**
- Change default mode: `useState<"voice" | "text">("voice")` (was `"text"`)
- Add `thought` state: `const [thought, setThought] = useState("")` for text input value
- Add `processingStage` state: `const [processingStage, setProcessingStage] = useState<"uploading" | "transcribing" | "classifying" | null>(null)` for granular feedback
- REMOVE `followUpMode` state -- the `mode` state now serves both primary capture and follow-up. When `agentQuestion` is set, `mode` controls follow-up input type.
- REMOVE `currentStep`, `completedSteps`, `showSteps` state variables (replaced by `processingStage`)
- REMOVE `streamedText` state (the AgentSteps feedback area is being replaced by the simpler processing stage display)

**Constants:**
- REMOVE `AGENT_STEPS` constant (no longer used)
- REMOVE `showComingSoon` function (Photo/Video buttons gone)

**Reset function:**
- Rename `resetVoiceState` to `resetState`
- Add `setThought("")` to clear text input
- Add `setProcessingStage(null)` to clear processing stage
- Replace `setFollowUpMode("voice")` with `setMode("voice")` to reset mode back to voice (default)
- Remove `setCurrentStep(null)`, `setCompletedSteps([])`, `setStreamedText("")`, `setShowSteps(false)` (these states no longer exist)

**Voice capture handler (handleRecordToggle) -- update callbacks:**
- On record stop, set `setProcessingStage("uploading")` immediately (instead of `setShowSteps(true)`)
- In `onStepStart` callback: set `setProcessingStage("classifying")`
- In `onStepFinish` callback: no-op (stage transitions on result event)
- Remove `onTextDelta` callback (no streaming text display)
- In `onLowConfidence`: set `setProcessingStage(null)` instead of `setShowSteps(true)`. Show bucket buttons by setting `setHitlInboxItemId` and `setHitlQuestion` as before.
- In `onMisunderstood`: set `setProcessingStage(null)` instead of `setShowSteps(false)`
- In `onUnresolved`: set `setProcessingStage(null)`
- In `onComplete`: set `setProcessingStage(null)`
- In `onError`: set `setProcessingStage(null)` instead of `setShowSteps(false)`

**New text capture handler (handleTextSubmit):**
Merge from `capture/text.tsx` handleSubmit logic. Create a `handleTextSubmit` callback:
```tsx
const handleTextSubmit = useCallback(() => {
  if (!thought.trim() || processing) return;
  if (!API_KEY) {
    setToast({ message: "No API key configured", type: "error" });
    return;
  }

  setProcessing(true);
  setProcessingStage("classifying");
  Haptics.impactAsync(Haptics.ImpactFeedbackStyle.Medium);

  const captureResult = sendCapture({
    message: thought.trim(),
    apiKey: API_KEY,
    callbacks: {
      onStepStart: () => setProcessingStage("classifying"),
      onStepFinish: () => {},
      onLowConfidence: (inboxItemId, bucket, _confidence) => {
        setHitlInboxItemId(inboxItemId);
        setHitlQuestion(`Best guess: ${bucket}. Which bucket?`);
        setProcessing(false);
        setProcessingStage(null);
        setHitlTopBuckets([bucket]);
      },
      onMisunderstood: (_threadId, questionText, inboxItemId) => {
        setAgentQuestion(questionText);
        setMisunderstoodInboxItemId(inboxItemId);
        setFollowUpRound(1);
        setThought("");
        setProcessing(false);
        setProcessingStage(null);
      },
      onUnresolved: () => {
        setProcessing(false);
        setProcessingStage(null);
        setToast({ message: "Couldn't classify. Check inbox later.", type: "error" });
        setTimeout(resetState, AUTO_RESET_MS);
      },
      onComplete: (result) => {
        setProcessing(false);
        setProcessingStage(null);
        Haptics.notificationAsync(Haptics.NotificationFeedbackType.Success);
        setToast({ message: result || "Captured", type: "success" });
        setTimeout(resetState, AUTO_RESET_MS);
      },
      onError: (error) => {
        setProcessing(false);
        setProcessingStage(null);
        setToast({ message: error || "Couldn't file your capture. Try again.", type: "error" });
      },
    },
  });
  cleanupRef.current = captureResult.cleanup;
}, [thought, processing, resetState]);
```

**Follow-up handlers:**
- In `handleFollowUpSubmit` (text follow-up): replace `setShowSteps(true)` with no-op (processing indicator not needed for follow-up since it's quick), replace `setShowSteps(false)` with no-op, remove `setCurrentStep`/`setCompletedSteps`/`setStreamedText` calls
- In `handleVoiceFollowUp` (voice follow-up): same cleanup of removed state setters
- In `handleFollowUpRecordToggle`: unchanged (it uses `isRecording` and delegates to `handleVoiceFollowUp`)
- The follow-up toggle links ("Type instead" / "Record instead") are being replaced by the top toggle buttons. During follow-up, the `mode` state controls which follow-up input renders. Remove all `setFollowUpMode` calls and instead just use `setMode`.

**JSX layout -- complete rewrite of the return statement:**

```
<SafeAreaView>
  {/* Toast overlay */}
  {toast && <ToastView ... />}

  {/* Voice/Text toggle row -- ALWAYS visible */}
  <View style={toggleRow}>
    <Pressable style={[toggleButton, mode === "voice" && toggleActive]}
      onPress={() => setMode("voice")}>
      <Text style={toggleIcon}>üéôÔ∏è</Text>
      <Text style={toggleLabel}>Voice</Text>
    </Pressable>
    <Pressable style={[toggleButton, mode === "text" && toggleActive]}
      onPress={() => setMode("text")}>
      <Text style={toggleIcon}>‚úçÔ∏è</Text>
      <Text style={toggleLabel}>Text</Text>
    </Pressable>
  </View>

  {/* Main content area */}
  <View style={contentArea}>

    {/* Agent question bubble -- shown during HITL follow-up */}
    {agentQuestion && (
      <AgentQuestionBubble ... />
    )}

    {/* Processing stage indicator -- replaces record button/text input during processing */}
    {processingStage && (
      <View style={processingArea}>
        <ActivityIndicator size="large" color="#4a90d9" />
        <Text style={processingStageText}>
          {processingStage === "uploading" ? "Uploading..." :
           processingStage === "classifying" ? "Classifying..." :
           "Processing..."}
        </Text>
      </View>
    )}

    {/* Voice mode content (record button, timer) -- hidden during processing and HITL question */}
    {mode === "voice" && !processingStage && !agentQuestion && (
      <VoiceRecordSection ... />  // existing record button + timer + hint
    )}

    {/* Text mode content (text input + send button) -- hidden during processing */}
    {mode === "text" && !processingStage && !agentQuestion && (
      <TextInputSection ... />  // text input with embedded Send button
    )}

    {/* Voice follow-up (record button for reply) -- shown during HITL follow-up in voice mode */}
    {agentQuestion && mode === "voice" && (
      <FollowUpVoiceSection ... />  // smaller record button for follow-up
    )}

    {/* Text follow-up (text input for reply) -- shown during HITL follow-up in text mode */}
    {agentQuestion && mode === "text" && (
      <FollowUpTextSection ... />  // text input for follow-up reply
    )}

    {/* Bucket selection buttons -- shown for low-confidence classification */}
    {hitlQuestion !== null && (
      <BucketSelectionSection ... />  // 4 bucket buttons
    )}

    {isResolving && <FilingText />}
  </View>
</SafeAreaView>
```

**Toggle button styles (new):**
```tsx
toggleRow: {
  flexDirection: "row",
  paddingHorizontal: 16,
  paddingTop: 12,
  paddingBottom: 8,
  gap: 12,
},
toggleButton: {
  flex: 1,
  height: 72,
  justifyContent: "center",
  alignItems: "center",
  backgroundColor: "#1a1a2e",
  borderRadius: 16,
  borderWidth: 2,
  borderColor: "transparent",
  overflow: "hidden",  // Prevent emoji clipping
},
toggleActive: {
  borderColor: "#4a90d9",
},
toggleIcon: {
  fontSize: 32,
  marginBottom: 4,
},
toggleLabel: {
  fontSize: 14,
  fontWeight: "600",
  color: "#ffffff",
},
```

**Text input area styles (new):**
```tsx
textInputContainer: {
  backgroundColor: "#1a1a2e",
  borderRadius: 12,
  padding: 12,
  minHeight: 120,
  position: "relative",
},
textInput: {
  fontSize: 18,
  color: "#ffffff",
  paddingBottom: 40,
  minHeight: 80,
  textAlignVertical: "top",
},
sendButton: {
  position: "absolute",
  bottom: 10,
  right: 10,
  backgroundColor: "#4a90d9",
  paddingHorizontal: 16,
  paddingVertical: 8,
  borderRadius: 8,
},
sendButtonText: {
  color: "#ffffff",
  fontSize: 15,
  fontWeight: "600",
},
```

**Processing stage styles (new):**
```tsx
processingArea: {
  flex: 1,
  justifyContent: "center",
  alignItems: "center",
},
processingStageText: {
  fontSize: 16,
  color: "#999",
  marginTop: 12,
},
```

**Content area style (new):**
```tsx
contentArea: {
  flex: 1,
  paddingHorizontal: 16,
},
```

**Styles to REMOVE:** `buttonStack`, `buttonRow` (replaced by `toggleRow`), all `AgentSteps`-related styles (`feedbackArea` that contained AgentSteps), `streamContainer`, `streamedText`.

**Important gotchas (from RESEARCH.md pitfalls):**
1. Mic permission: The `useEffect` that requests mic permission runs when `mode === "voice"`. Since default is now `"voice"`, it runs on mount -- this is correct. Ensure the effect is preserved.
2. `sendCapture` returns `{ cleanup, threadId }` -- store `captureResult.cleanup` in `cleanupRef.current`.
3. `setThought("")` must be in `resetState` to clear text input after filing.
4. During follow-up, `mode` controls the follow-up input type. The top toggle buttons call `setMode()` which switches the follow-up input.
5. The `hitlQuestion` bucket buttons must NOT be gated on `showSteps` anymore (that state is removed). Instead, show them whenever `hitlQuestion !== null`.
  </action>
  <verify>
    <automated>cd /Users/willmacdonald/Documents/Code/claude/second-brain/mobile && npx tsc --noEmit 2>&1 | head -30</automated>
  </verify>
  <done>
    - `(tabs)/index.tsx` renders two equal-size Voice/Text toggle buttons at the top with Voice pre-selected
    - Text mode shows text input with "What's on your mind?" placeholder and embedded Send button
    - Voice mode shows the existing record button centered in content area
    - Processing stages display "Uploading...", "Classifying..." with ActivityIndicator
    - Follow-up mode uses top Voice/Text toggles (no "Type instead" / "Record instead" links)
    - No Photo/Video buttons, no CaptureButton import, no AgentSteps import, no router import
    - `sendCapture` imported and wired for text capture flow
    - TypeScript compiles with no errors
  </done>
</task>

<task type="auto">
  <name>Task 2: Delete redundant files and clean up routing</name>
  <files>mobile/app/capture/text.tsx, mobile/app/_layout.tsx, mobile/components/CaptureButton.tsx, mobile/components/AgentSteps.tsx</files>
  <action>
1. **Delete `mobile/app/capture/text.tsx`** -- all text capture functionality is now in `(tabs)/index.tsx`.

2. **Delete `mobile/app/capture/` directory** if it is now empty.

3. **Delete `mobile/components/CaptureButton.tsx`** -- the 4-button grid is replaced by inline toggle buttons. Verify no other file imports `CaptureButton` before deleting (grep for `CaptureButton` across mobile/ -- only `(tabs)/index.tsx` and `capture/text.tsx` use it, and both have been updated/deleted).

4. **Delete `mobile/components/AgentSteps.tsx`** -- the pill-dot step indicator is replaced by the simpler `processingStage` text display with `ActivityIndicator`. Verify no other file imports `AgentSteps` before deleting (grep for `AgentSteps` across mobile/ -- only `(tabs)/index.tsx` and `capture/text.tsx` use it).

5. **Update `mobile/app/_layout.tsx`** -- remove the `capture/text` Stack.Screen:

Remove this block:
```tsx
<Stack.Screen
  name="capture/text"
  options={{
    headerShown: true,
    headerTitle: "",
    headerStyle: { backgroundColor: "#0f0f23" },
    headerTintColor: "#ffffff",
    presentation: "modal",
  }}
/>
```

The resulting `_layout.tsx` should only have `(tabs)` and `conversation/[threadId]` Stack.Screens.
  </action>
  <verify>
    <automated>cd /Users/willmacdonald/Documents/Code/claude/second-brain/mobile && npx tsc --noEmit 2>&1 | head -30 && test ! -f app/capture/text.tsx && echo "text.tsx deleted" && test ! -f components/CaptureButton.tsx && echo "CaptureButton deleted" && test ! -f components/AgentSteps.tsx && echo "AgentSteps deleted"</automated>
  </verify>
  <done>
    - `capture/text.tsx` deleted (and `capture/` directory if empty)
    - `CaptureButton.tsx` component deleted
    - `AgentSteps.tsx` component deleted
    - `_layout.tsx` no longer references `capture/text` route
    - TypeScript compiles with no errors (no broken imports anywhere)
  </done>
</task>

</tasks>

<verification>
1. `npx tsc --noEmit` passes with zero errors
2. No file in `mobile/` imports `CaptureButton`, `AgentSteps`, or references `capture/text`
3. `(tabs)/index.tsx` imports `sendCapture` from ag-ui-client
4. `(tabs)/index.tsx` default mode is `"voice"`
5. No "Type instead" or "Record instead" text exists in the codebase
6. No "Photo" or "Video" or "Coming soon" text exists in capture screen
</verification>

<success_criteria>
The unified capture screen:
- Shows Voice/Text toggles at top with Voice pre-selected
- Text mode: text input with embedded Send button, sends via `sendCapture`
- Voice mode: record button with timer, sends via `sendVoiceCapture`
- Processing shows granular stages (Uploading/Classifying) with spinner
- Follow-up uses top toggles for mode switching (no inline links)
- Low-confidence bucket buttons appear inline
- No navigation to separate text screen
- Dead code (text.tsx, CaptureButton, AgentSteps, Photo/Video) removed
- TypeScript compiles cleanly
</success_criteria>

<output>
After completion, create `.planning/phases/09.1-mobile-ux-review-and-refinements/09.1-01-SUMMARY.md`
</output>
